{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import cobra\n",
    "import cobra.test\n",
    "# import mackinac\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from cobra.flux_analysis import gapfill\n",
    "from cobra.flux_analysis import pfba\n",
    "from cobra.flux_analysis.parsimonious import add_pfba\n",
    "from cobra.flux_analysis import sample\n",
    "from cobra.core.solution import get_solution\n",
    "\n",
    "# Set default logger to python logger to avoid warnings given when adding reactions and/or metaboites \n",
    "# because \"cobra.core.model\" doesn't innately have a logger.\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_media(model, media, universal, verbose=False):\n",
    "\n",
    "    # Find and close all exchange reactions in the model\n",
    "    model_rxns = [rxn.id for rxn in model.reactions]\n",
    "    for rxn in model_rxns:\n",
    "        if rxn.startswith('EX_') and rxn.endswith('_e'):\n",
    "            model.reactions.get_by_id(rxn).lower_bound = 0.0\n",
    "\n",
    "    # Check for existence of exchange reactions for the media metabolites in the model\n",
    "    for metabolite in media:\n",
    "        met = metabolite[1]+'_e'\n",
    "        if 'EX_'+met in model_rxns:\n",
    "            model.reactions.get_by_id('EX_'+met).lower_bound = -1000.\n",
    "        else:\n",
    "            # Create exchange reaction and add to model\n",
    "            if verbose:\n",
    "                print(\"added exchange rxn for \" + met)\n",
    "            new_exchange = cobra.Reaction('EX_'+met)\n",
    "            new_exchange.name = met + ' exchange'\n",
    "            met_obj = universal.metabolites.get_by_id(met)\n",
    "            new_exchange.add_metabolites({met_obj:-1})\n",
    "            new_exchange.lower_bound = -1000.\n",
    "            new_exchange.upper_bound = 1000.\n",
    "            model.add_reaction(new_exchange)\n",
    "            model.repair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in list of genome IDs\n",
    "with open('../Data/20_species_1023_genomes.csv') as csvfile:\n",
    "    genome_ids_list = []\n",
    "    for line in csvfile:\n",
    "        genome_ids_list.append(line.strip())\n",
    "len(genome_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize functions\n",
    "# Initialize global variables\n",
    "# Set media cpds\n",
    "# Open model\n",
    "# Add water transporter and fix name\n",
    "# loop: Change media\n",
    "    # turn off all exchanges\n",
    "    # Turn on correct exchanges, add if missing\n",
    "    \n",
    "    # Loop: Set demand reaction\n",
    "        # Check for production\n",
    "        # Gapfill with probanno\n",
    "        # Determine the reactions that were added to gapfill and identify the likelihoods\n",
    "        # Optimize and find solution\n",
    "        # Average likelihoods to create metric for media condition and specific demand reaction\n",
    "        # save information in data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "# Ensure free water exhange\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources\n",
    "set_media(model, media_list, universal, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop')\n",
    "for aa_list in aas:\n",
    "    sys.stdout.write('\\n'+ str(counter))\n",
    "    aa = aa_list[1]+'_c'\n",
    "    # Add Demand Reaction for metabolite\n",
    "    metabolite = model.metabolites.get_by_id(aa)\n",
    "    demand = model.add_boundary(metabolite, type='demand')\n",
    "    model.objective = demand\n",
    "    # Gapfill\n",
    "    sys.stdout.write('...gapfilling...')\n",
    "    gaps_to_fill = gapfill(model, universal, demand_reactions=False) # Update to probannopy gapfill function; use Gurobi\n",
    "    # Fill the gaps\n",
    "    rxns_to_add = []\n",
    "    for gap in gaps_to_fill:\n",
    "        model.add_reactions(gap) ### I NEED TO REMOVE THESE REACTIONS\n",
    "    # Optimize with full pathway\n",
    "    sys.stdout.write('optimizing...')\n",
    "    solution = model.optimize()\n",
    "    # Find reactions that carry flux and their likelihood score\n",
    "    df = solution.fluxes.to_frame()\n",
    "    active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "    like_list = []\n",
    "    for rxn in list(active.index):\n",
    "        if rxn.startswith('rxn'):\n",
    "            try:\n",
    "                like_list.append(likelihoods[rxn])\n",
    "            except:\n",
    "                pass\n",
    "    avg_like = np.mean(like_list)\n",
    "    sys.stdout.write('Average Likelihood of: ' + aa_list[1] + ' is ' + str(avg_like))\n",
    "    aa_like[aa_list[1]] = avg_like\n",
    "    model.remove_reactions([demand])\n",
    "    # ADD REMOVAL OF GAPS\n",
    "    counter += 1\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"Time to complete:\" + str(elapsed/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no demand or exchange reactions in the universal reaction bag\n",
    "for rxn in universal.reactions:\n",
    "    if rxn.id.startswith('DM'):\n",
    "        print('DM in reaction bag')\n",
    "    elif rxn.id.startswith('EX'):\n",
    "        print('EX in reaction bag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_to_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihoods['rxn00898_c'])\n",
    "print(likelihoods['rxn02186_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_likes = []\n",
    "passed_rxns = []\n",
    "counter = 0\n",
    "pass_counter = 0\n",
    "for rxn in model.reactions:\n",
    "    if rxn.id.startswith('rxn'):\n",
    "        try:\n",
    "            all_likes.append(likelihoods[rxn.id])\n",
    "            counter += 1\n",
    "        except:\n",
    "            passed_rxns.append(rxn.id)\n",
    "            pass_counter += 1\n",
    "            pass\n",
    "global_avg = np.mean(all_likes)\n",
    "\n",
    "print(global_avg)\n",
    "print(counter)\n",
    "print(pass_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_rxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.reactions.get_by_id('rxn02374_c').name)\n",
    "print(model.reactions.get_by_id('rxn05319_c').name)\n",
    "print(model.reactions.get_by_id('rxn04457_c').name)\n",
    "print(model.reactions.get_by_id('rxn02916_c').name)\n",
    "print(model.reactions.get_by_id('rxn03012_c').name)\n",
    "print(model.reactions.get_by_id('rxn10571_c').name)\n",
    "print(model.reactions.get_by_id('rxn04132_c').name)\n",
    "print(model.reactions.get_by_id('rxn05195_c').name)\n",
    "print(model.reactions.get_by_id('rxn05468_c').name)\n",
    "print(model.reactions.get_by_id('rxn04133_c').name)\n",
    "print(model.reactions.get_by_id('rxn05467_c').name)\n",
    "print(model.reactions.get_by_id('rxn12215_c').name)\n",
    "print(model.reactions.get_by_id('rxn05522_c').name)\n",
    "print(model.reactions.get_by_id('rxn08688_c').name)\n",
    "print(model.reactions.get_by_id('rxn05238_c').name)\n",
    "print(model.reactions.get_by_id('rxn02976_c').name)\n",
    "print(model.reactions.get_by_id('rxn08764_c').name)\n",
    "print(model.reactions.get_by_id('rxn13022_c').name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.reactions.get_by_id('rxn02374_c').name)\n",
    "# print(model.reactions.get_by_id('rxn05319_c').name)\n",
    "print(model.reactions.get_by_id('rxn04457_c').name)\n",
    "print(model.reactions.get_by_id('rxn02916_c').name)\n",
    "print(model.reactions.get_by_id('rxn03012_c').name)\n",
    "# print(model.reactions.get_by_id('rxn10571_c').name)\n",
    "print(model.reactions.get_by_id('rxn04132_c').name)\n",
    "# print(model.reactions.get_by_id('rxn05195_c').name)\n",
    "print(model.reactions.get_by_id('rxn05468_c').name)\n",
    "print(model.reactions.get_by_id('rxn04133_c').name)\n",
    "# print(model.reactions.get_by_id('rxn05467_c').name)\n",
    "# print(model.reactions.get_by_id('rxn12215_c').name)\n",
    "# print(model.reactions.get_by_id('rxn05522_c').name)\n",
    "# print(model.reactions.get_by_id('rxn08688_c').name)\n",
    "print(model.reactions.get_by_id('rxn05238_c').name)\n",
    "print(model.reactions.get_by_id('rxn02976_c').name)\n",
    "# print(model.reactions.get_by_id('rxn08764_c').name)\n",
    "# print(model.reactions.get_by_id('rxn13022_c').name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn02374_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn04457_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn02916_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn03012_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn04132_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn05468_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn04133_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn05238_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('rxn02976_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off O2 exchange\n",
    "model.reactions.get_by_id('EX_cpd00007_e').lower_bound = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basal Synthetic Media\n",
    "bsm = [\n",
    "    ['H+','cpd00067'],\n",
    "    ['H2O','cpd00001'],\n",
    "    ['CO2','cpd00011'],\n",
    "    ['O2','cpd00007'],\n",
    "    ['N2','cpd00528'], \n",
    "#     ['H2','cpd11640'], # Only with no O2\n",
    "    \n",
    "    ['K+','cpd00205'],\n",
    "    ['Na+','cpd00971'],\n",
    "    ['Mg','cpd00254'],\n",
    "    ['Mn2+','cpd00030'],\n",
    "    ['Fe2+','cpd10515'], # Iron ion in heme\n",
    "    ['Ca2+','cpd00063'], # Calcium pantothenate;cpd19112\n",
    "    \n",
    "    ['Vitamin B12r','cpd00423'], # C62H91CoN13O14P : cobalamin;cpd03424;cpd00730 : not present in any exchange reactions\n",
    "    ['Cobinamide','cpd03422'], #EXs : related to cobalamin (B12) Added to ensure cells have access to B12\n",
    "    ['BIOT','cpd00104'], # C10H15N2O3S : biotin B7\n",
    "    ['PAN','cpd00644'], # C9H16NO5 : Pantothenate B5\n",
    "    ['Folate','cpd00393'], # C19H17N7O6 : B9\n",
    "    ['Niacin','cpd00218'], # C6H4NO2 : B3\n",
    "    ['Pyridoxal','cpd00215'], # C8H9NO3 : B6\n",
    "    ['Riboflavin','cpd00220'], # C17H19N4O6 : B2\n",
    "    ['thiamin','cpd00305'], # C12H17N4OS : B1\n",
    "    \n",
    "#     ['Phosphate','cpd00009'], # HO4P : In M9 Defaults\n",
    "    \n",
    "    ['Thioglycolate','cpd01415'], # C2H3O2S : not present in any exchange reactions\n",
    "#     ['Sulfate','cpd00048'], # O4S : In M9 Defaults\n",
    "    \n",
    "    ['Acetate','cpd00029'], # C2H3O2 : not present in any exchange reactions\n",
    "    ['Citrate','cpd00137'], # C6H5O7 : Consider removing. \n",
    "#     ['Polysorbate 60','cpd24450'], # C35H68O10 : Almost tween 80 : not present in any reactions\n",
    "#     ['Ethyl acetate','cpd00633'], # C4H8O2 : not present in any exchange reactions, only present in one reaction at all\n",
    "    \n",
    "    ['ABEE','cpd00443'] # C7H6NO2 : aminobenzoate : not present in any exchange reactions\n",
    "]\n",
    "\n",
    "# Potentially add to BSM (from M9 media)\n",
    "M9_ions = [\n",
    "    ['Cl-','cpd00099'],\n",
    "    ['Co2+','cpd00149'],\n",
    "    ['Cu2+','cpd00058'],\n",
    "    ['Fe3','cpd10516'],\n",
    "#     ['Sodium molybdate','cpd11145'], # This doesn't connect to anything\n",
    "    ['Ni2+','cpd00244'],\n",
    "    ['Selenate','cpd03396'],\n",
    "    ['Selenite','cpd03387'],\n",
    "    ['Zn2+','cpd00034']\n",
    "]\n",
    "\n",
    "# Enviromental Metabolites with Exchange reactions\n",
    "[\n",
    "#     ['CO2','cpd00011'], #EXs : \n",
    "#     ['Ca2+','cpd00063'], #EXs : \n",
    "#     ['Cd2+','cpd01012'], #EXs : Removed because toxic\n",
    "#     ['chromate','cpd11595'], #EXs : Removed because toxic\n",
    "#     ['Cl-','cpd00099'], #EXs : \n",
    "#     ['Co2+','cpd00149'], #EXs : In M9\n",
    "#     ['Cu2+','cpd00058'], #EXs : In M9\n",
    "#     ['Fe2+','cpd10515'], #EXs : \n",
    "#     ['H+','cpd00067'], #EXs : \n",
    "#     ['H2','cpd11640'], #EXs : \n",
    "#     ['H2O','cpd00001'], #EXs : \n",
    "#     ['Hg2+','cpd00531'], #EXs : Removed because toxic\n",
    "#     ['K+','cpd00205'], #EXs : \n",
    "#     ['Mg','cpd00254'], #EXs : \n",
    "#     ['Mn2+','cpd00030'], #EXs : \n",
    "#     ['Na+','cpd00971'], #EXs : \n",
    "#     ['Ni2+','cpd00244'], #EXs : In M9\n",
    "#     ['O2','cpd00007'], #EXs : \n",
    "#     ['Pb','cpd04097'], #EXs : Removed because toxic\n",
    "#     ['Zn2+','cpd00034'], #EXs : In M9\n",
    "#     ['fe3','cpd10516'] #EXs : In M9\n",
    "]\n",
    "\n",
    "# M9 Base : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4932939/\n",
    "# [\n",
    "#     ['Ca2+','cpd00063'],\n",
    "#     ['Cl-','cpd00099'],\n",
    "#     ['CO2','cpd00011'],\n",
    "#     ['Co2+','cpd00149'],\n",
    "#     ['Cu2+','cpd00058'],\n",
    "#     ['Fe2+','cpd10515'],\n",
    "#     ['Fe3','cpd10516'],\n",
    "#     ['H+','cpd00067'],\n",
    "#     ['H2O','cpd00001'],\n",
    "#     ['K+','cpd00205'],\n",
    "#     ['Mg','cpd00254'],\n",
    "#     ['Mn2+','cpd00030'],\n",
    "#     ['Sodium molybdate','cpd11145'],\n",
    "#     ['Na+','cpd00971'],\n",
    "#     ['Ni2+','cpd00244'],\n",
    "#     ['Selenate','cpd03396'],\n",
    "#     ['Selenite','cpd03387'],\n",
    "#     ['Zn2+','cpd00034']\n",
    "# ]\n",
    "\n",
    "# M9 default carbon, nitrogen, phosphorous, and sulfur sources\n",
    "M9_sources = [\n",
    "    ['D-Glucose','cpd00027'],\n",
    "    ['NH3','cpd00013'], # this is actually NH4 : ammonium\n",
    "    ['Phosphate','cpd00009'],\n",
    "    ['Sulfate','cpd00048']\n",
    "]\n",
    "\n",
    "# Vitamins\n",
    "vit_k = [\n",
    "#     ['BIOT','cpd00104'], #EXs : Biotin\n",
    "#     ['Cobinamide','cpd03422'], #EXs : related to cobalamin (B12)\n",
    "#     ['Folate','cpd00393'], #EXs : \n",
    "    ['Menaquinone 7','cpd11606'], #EXs : Vitamine K2 : Add when there is no O2\n",
    "#     ['Niacin','cpd00218'], #EXs : \n",
    "#     ['PAN','cpd00644'], #EXs : Pantothenate\n",
    "#     ['Pyridoxal','cpd00215'], #EXs : \n",
    "#     ['Riboflavin','cpd00220'], #EXs : \n",
    "#     ['Thiamin','cpd00305'] #EXs : \n",
    "]\n",
    "\n",
    "# For aerobic simulations, O2 was added with a lower bound of −20 and to 0 for anaerobic simulations.\n",
    "\n",
    "# DNA/RNA related metabolites\n",
    "rna_bases = [\n",
    "#     ['35ccmp','cpd00696'], #EXs : \n",
    "#     ['AMP','cpd00018'], #EXs : \n",
    "    ['Adenosine','cpd00182'], #EXs : In BSM (as adenine)\n",
    "#     ['Adenosine 3-5-bisphosphate','cpd00045'], #EXs : \n",
    "    ['Cytosine','cpd00307'], #EXs : \n",
    "#     ['Deoxyadenosine','cpd00438'], #EXs : \n",
    "#     ['Deoxycytidine','cpd00654'], #EXs : \n",
    "#     ['Deoxyguanosine','cpd00277'], #EXs : In BSM\n",
    "#     ['Deoxyinosine','cpd03279'], #EXs : \n",
    "#     ['Deoxyuridine','cpd00412'], #EXs : \n",
    "#     ['GMP','cpd00126'], #EXs : \n",
    "#     ['GTP','cpd00038'], #EXs : \n",
    "    ['Guanosine','cpd00311'], #EXs : In BSM (as Guanine)\n",
    "#     ['Inosine','cpd00246'], #EXs : \n",
    "#     ['HYXN','cpd00226'], #EXs : Hypoxanthine\n",
    "#     ['Nicotinamide ribonucleotide','cpd00355'], #EXs : \n",
    "#     ['TTP','cpd00357'], #EXs : Deoxythymidine triphosphate\n",
    "    ['Thymidine','cpd00184'], #EXs : In BSM\n",
    "#     ['Thyminose','cpd01242'], #EXs : deoxyribose\n",
    "#     ['Uracil','cpd00092'], #EXs : \n",
    "    ['Uridine','cpd00249'], #EXs : In BSM (as uracil)\n",
    "#     ['XAN','cpd00309'], #EXs : Xanthine\n",
    "#     ['Xanthosine','cpd01217'], #EXs : \n",
    "#     ['dATP','cpd00115'], #EXs : \n",
    "#     ['dGTP','cpd00241'], #EXs : \n",
    "#     ['dTMP','cpd00298'] #EXs : \n",
    "]\n",
    "\n",
    "# Check to see if these metabolites are used in pathways? Should I add some of these to media? \n",
    "# Yes for ATP, and GTP. (TTP, CTP as well?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm + M9_sources + rna_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carbon Sources from all Exchanges and additional interesting sources\n",
    "[\n",
    "    ['4-Hydroxybenzoate','cpd00136'], #EXs : found in coconuts\n",
    "    ['2-keto-3-deoxygluconate','cpd00176'], #EXs : degraded pectin product\n",
    "    ['Amylotriose','cpd01262'], #EXs : \n",
    "    ['CELB','cpd00158'], #EXs : Cellobiose\n",
    "    ['D-Fructose','cpd00082'], #EXs : \n",
    "    ['D-Glucose','cpd00027'], #EXs : \n",
    "    ['D-Mannitol','cpd00314'], #EXs : sweetener the is poorly absorbed in the gut\n",
    "    ['D-Mannose','cpd00138'], #EXs : related to mucin\n",
    "    ['Ribose','cpd00105'], #EXs : \n",
    "    ['Dextrin','cpd11594'], #EXs : \n",
    "    ['Dulcose','cpd01171'], #EXs : Galactitol\n",
    "    ['GLCN','cpd00222'], #EXs : Gluconate \n",
    "    ['GLUM','cpd00276'], #EXs : Glucosamine\n",
    "    ['Galactose','cpd00108'], #EXs : \n",
    "    ['L-Arabinose','cpd00224'], #EXs : \n",
    "    ['L-Inositol','cpd00121'], #EXs : \n",
    "    ['L-Lactate','cpd00159'], #EXs : \n",
    "    ['L-Malate','cpd00130'], #EXs : \n",
    "    ['Glycerol','cpd00100'], #EXs : \n",
    "    ['LACT','cpd00208'], #EXs : lactose\n",
    "    ['Maltohexaose','cpd01329'], #EXs : \n",
    "    ['Maltose','cpd00179'], #EXs : \n",
    "    ['Melibiose','cpd03198'], #EXs :\n",
    "    ['Palmitate','cpd00214'], #EXs : \n",
    "    ['Propionate','cpd00141'], #EXs : \n",
    "    ['Salicin','cpd01030'], #EXs : \n",
    "    ['Sorbitol','cpd00588'], #EXs : \n",
    "    ['Stachyose','cpd01133'], #EXs : \n",
    "    ['Succinate','cpd00036'], #EXs : \n",
    "    ['Sucrose','cpd00076'], #EXs : \n",
    "    ['TRHL','cpd00794'], #EXs : Trehalose\n",
    "    ['Ursin','cpd03696'], #EXs : Arbutin\n",
    "    ['Xylose','cpd00154'], #EXs : \n",
    "    ['hexadecenoate','cpd15237'] #EXs : \n",
    "]\n",
    "\n",
    "# Nitrogen Sources\n",
    "[\n",
    "#     ['NH3','cpd00013'], #EXs : \n",
    "    ['Allantoin','cpd01092'], #EXs : degradation product of purines\n",
    "    ['BET','cpd00540'], #EXs : Betaine\n",
    "    ['Choline','cpd00098'], #EXs : Found in milk\n",
    "    ['GABA','cpd00281'], #EXs : Could also be a carbon source\n",
    "    ['Nitrate','cpd00209'], #EXs : \n",
    "    ['Nitrite','cpd00075'], #EXs : \n",
    "    ['Spermidine','cpd00264'], #EXs : \n",
    "    ['Urea','cpd00073'], #EXs : \n",
    "    ['crotonobetaine','cpd08305'] #EXs : \n",
    "]\n",
    "\n",
    "# Sulfur Sources\n",
    "[\n",
    "    ['H2S2O3','cpd00268'], #EXs : Thiosulfate\n",
    "    ['Isethionate','cpd03048'], #EXs : C2H5O4S\n",
    "#     ['Sulfate','cpd00048'], #EXs : O4S\n",
    "    ['Sulfite','cpd00081'], #EXs : HO3S\n",
    "    ['Sulfoacetate','cpd09878'], #EXs : C2H2O5S\n",
    "    ['ethanesulfonate','cpd11579'], #EXs : C2H5O3S\n",
    "    ['methanesulfonate','cpd08023'] #EXs : CH3O3S\n",
    "]\n",
    "\n",
    "# Phosphorus Sources\n",
    "[\n",
    "    ['Phosphate','cpd00009'] #EX :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amino Acid related metabolites\n",
    "aas = [\n",
    "    ['D-Alanine','cpd00117'], #EXs : \n",
    "    ['D-Glutamate','cpd00186'], #EXs : \n",
    "    ['D-Methionine','cpd00637'], #EXs : \n",
    "    ['D-Serine','cpd00550'], #EXs : \n",
    "    ['Glycine','cpd00033'], #EXs : 1\n",
    "    ['L-Alanine','cpd00035'], #EXs : 2\n",
    "    ['L-Arginine','cpd00051'], #EXs : 3\n",
    "    ['L-Asparagine','cpd00132'], #EXs : 4\n",
    "    ['L-Aspartate','cpd00041'], #EXs : 5\n",
    "\n",
    "    ['L-Cysteine','cpd00084'], #EXs : 7\n",
    "    ['L-Glutamate','cpd00023'], #EXs : 8\n",
    "    ['L-Glutamine','cpd00053'], #EXs : 9\n",
    "    ['L-Histidine','cpd00119'], #EXs : 10\n",
    "    ['L-Isoleucine','cpd00322'], #EXs : 11\n",
    "    ['L-Leucine','cpd00107'], #EXs : 12\n",
    "    ['L-Lysine','cpd00039'], #EXs : 13\n",
    "    ['L-Methionine','cpd00060'], #EXs : 14\n",
    "    ['L-Phenylalanine','cpd00066'], #EXs : 15\n",
    "    ['L-Proline','cpd00129'], #EXs : 16\n",
    "    ['L-Serine','cpd00054'], #EXs : 17\n",
    "    ['L-Threonine','cpd00161'], #EXs : 18\n",
    "    ['L-Tryptophan','cpd00065'], #EXs : 19\n",
    "    ['L-Tyrosine','cpd00069'], #EXs : 20\n",
    "    ['L-Valine','cpd00156'] #EXs : 21\n",
    "]\n",
    "# Explore leave one out with core amino acids. \n",
    "\n",
    "# Dimers, and other amino acid related mets\n",
    "aa_related = [\n",
    "    ['2-Oxoglutarate','cpd00024'], #EXs : \n",
    "    ['Ala-Gln','cpd11587'], #EXs : \n",
    "    ['Ala-His','cpd11584'], #EXs : \n",
    "    ['Ala-Leu','cpd11583'], #EXs : \n",
    "    ['ala-L-asp-L','cpd11593'], #EXs : \n",
    "    ['ala-L-glu-L','cpd11586'], #EXs : \n",
    "    ['ala-L-Thr-L','cpd11582'], #EXs : \n",
    "    ['Aminoethanol','cpd00162'], #EXs : Ethanolamine\n",
    "    ['Carnitine','cpd00266'], #EXs : \n",
    "    ['Chorismate','cpd00216'], #EXs : \n",
    "    ['L-Cysteate','cpd00395'], #EXs : \n",
    "    ['Cys-Gly','cpd01017'], #EXs : \n",
    "    ['Gly-Cys','cpd15603'], #EXs : \n",
    "    ['Gly-Gln','cpd11580'], #EXs : \n",
    "    ['Gly-Leu','cpd15604'], #EXs : \n",
    "    ['Gly-Met','cpd11591'], #EXs : \n",
    "    ['Gly-Phe','cpd15605'], #EXs : \n",
    "    ['Gly-Tyr','cpd15606'], #EXs : \n",
    "    ['gly-asn-L','cpd11581'], #EXs : \n",
    "    ['gly-asp-L','cpd11589'], #EXs : \n",
    "    ['gly-glu-L','cpd11592'], #EXs : \n",
    "    ['gly-pro-L','cpd11588'], #EXs : \n",
    "    ['L-Methionine S-oxide','cpd01914'], #EXs :\n",
    "    ['L-alanylglycine','cpd11585'], #EXs : \n",
    "    ['L-methionine R-oxide','cpd11576'], #EXs : \n",
    "    ['met-L-ala-L','cpd11590'], #EXs :\n",
    "    ['S-Adenosyl-L-methionine','cpd00017'], #EXs : \n",
    "    ['S-Methyl-L-methionine','cpd02027'], #EXs : \n",
    "    ['S-Ribosylhomocysteine','cpd02227'], #EXs : \n",
    "    ['N-Acetyl-D-glucosamine','cpd00122'], #EXs : \n",
    "    ['N-Acetyl-D-mannosamine','cpd00492'], #EXs : \n",
    "    ['Ornithine','cpd00064'], #EXs : \n",
    "    ['Putrescine','cpd00118'], #EXs : \n",
    "    ['Taurine','cpd00210'], #EXs : \n",
    "    ['meso-2,6-Diaminopimelate','cpd00516'] #EXs : related to lysine\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production\n",
    "# H2O2 -- cpd00025\n",
    "# Acetate -- cpd00029\n",
    "# Butyrate -- cpd00211\n",
    "# isobutyrate -- cpd01711\n",
    "# GABA -- cpd00281\n",
    "# ethanol -- cpd00363\n",
    "# Propionate -- cpd00141\n",
    "# formate -- cpd00047\n",
    "# Valerate -- cpd00597\n",
    "# Isovaleric acid -- cpd05178 (wrong eqn)\n",
    "# sulforaphane -- \n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5541232/\n",
    "# thiamin -- cpd00305\n",
    "# Pyridoxal phosphate (B6) -- cpd00016\n",
    "# BIOT (biotin, B7) -- cpd00104\n",
    "# (CH3)3NO (TMAO) -- cpd00811\n",
    "# Indole-3-(carb)aldehyde -- cpd05401\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4337795/\n",
    "# Acetaldehyde -- cpd00071\n",
    "# Deoxycholate -- cpd02733\n",
    "# Chorismate -- cpd00216\n",
    "# Hexanoate -- cpd01113\n",
    "# \n",
    "\n",
    "# Consumption\n",
    "# Galactose -- cpd00108; cpd01112\n",
    "# L-galactose -- cpd01257\n",
    "# lactose -- cpd00208\n",
    "# beta-lactose -- cpd01354\n",
    "# sucrose -- cpd00076\n",
    "# trehalose (TRHL) -- cpd00794\n",
    "# maltose -- cpd00179\n",
    "# D-Mannose -- cpd00138\n",
    "# D-Fructose -- cpd00082\n",
    "# Inulin -- cpd27312\n",
    "# ethanol -- cpd00363\n",
    "# Carnitine -- cpd00266\n",
    "# Citrate -- cpd00137\n",
    "# GLUM (D-glucosamine) -- cpd00276\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pFBA\n",
    "\n",
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "# Ensure free water exhange\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources\n",
    "set_media(model, media_list, universal, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop')\n",
    "# for aa_list in aas[0:1]:\n",
    "\n",
    "sys.stdout.write('\\n'+ str(counter))\n",
    "# aa = aa_list[1]+'_c'\n",
    "aa = 'cpd00117_c'\n",
    "# Add Demand Reaction for metabolite\n",
    "metabolite = model.metabolites.get_by_id(aa)\n",
    "demand = model.add_boundary(metabolite, type='demand')\n",
    "model.objective = demand\n",
    "# Gapfill\n",
    "sys.stdout.write('...gapfilling...')\n",
    "gaps_to_fill = gapfill(model, universal, demand_reactions=False) # Update to probannopy gapfill function; use Gurobi\n",
    "# Fill the gaps\n",
    "rxns_to_add = []\n",
    "for gap in gaps_to_fill:\n",
    "    model.add_reactions(gap)\n",
    "# Optimize with full pathway\n",
    "sys.stdout.write('optimizing...')\n",
    "solution = pfba(model, objective = demand)\n",
    "# Find reactions that carry flux\n",
    "df = solution.fluxes.to_frame()\n",
    "active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "# Add demand reactions for any metabolites produced, but not consumed\n",
    "\n",
    "# Acquire likelihood scores for reactions that carry flux\n",
    "like_list = []\n",
    "rxns_w_likes = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            like_list.append(likelihoods[rxn])\n",
    "            rxns_w_likes.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "avg_like = np.mean(like_list)\n",
    "sys.stdout.write('Average Likelihood of: ' + aa_list[1] + ' is ' + str(avg_like))\n",
    "aa_like[aa_list[1]] = avg_like\n",
    "# Remove demand and filled gaps\n",
    "model.remove_reactions([demand])\n",
    "model.remove_reactions(gaps_to_fill[0]) # This might not work when multiple reactions are added... \n",
    "\n",
    "    ## Remove demands added to remove extra metabolites produced\n",
    "    \n",
    "counter += 1\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete:\" + str(elapsed/60) + \"mins\")\n",
    "print('\\n')\n",
    "print(gaps_to_fill)\n",
    "print(rxns_w_likes)\n",
    "print(like_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gaps_to_fill)\n",
    "print(rxns_w_likes)\n",
    "print(like_list)\n",
    "# print(likelihoods['rxn00904_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_list = []\n",
    "rxns_w_likes = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            like_list.append(likelihoods[rxn])\n",
    "            rxns_w_likes.append(rxn)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mets = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        print(rxn)\n",
    "        rxn_obj = model.reactions.get_by_id(rxn)\n",
    "        for met in rxn_obj.metabolites:\n",
    "            if (met.id.endswith('_c')) & (met.id != aa):\n",
    "                all_mets.append(met.id)\n",
    "all_mets = set(all_mets)\n",
    "all_mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolite = model.metabolites.get_by_id(aa)\n",
    "demand = model.add_boundary(metabolite, type='demand')\n",
    "model.objective = demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('DM_cpd00117_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in all_mets:\n",
    "    metabolite = model.metabolites.get_by_id(met)\n",
    "    model.add_boundary(metabolite, type='demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pfba(model, objective = demand)\n",
    "# Find reactions that carry flux\n",
    "df = solution.fluxes.to_frame()\n",
    "active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "# Add demand reactions for any metabolites produced, but not consumed\n",
    "\n",
    "# Acquire likelihood scores for reactions that carry flux\n",
    "like_list = []\n",
    "rxns_w_likes = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            like_list.append(likelihoods[rxn])\n",
    "            rxns_w_likes.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "avg_like = np.mean(like_list)\n",
    "sys.stdout.write('Average Likelihood of: ' + aa + ' is ' + str(avg_like))\n",
    "aa_like[aa_list[1]] = avg_like\n",
    "\n",
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rxns_w_likes)\n",
    "print(like_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reactions.get_by_id('DM_cpd00067_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in all_mets:\n",
    "    try:\n",
    "        model.remove_reactions([model.reactions.get_by_id('DM_'+met)])\n",
    "    except:\n",
    "        print('skipped')\n",
    "        print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.remove_reactions([model.reactions.get_by_id('DM_cpd00102_c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.reactions.get_by_id('DM_cpd00102_c')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_list = []\n",
    "rxns_w_likes = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            like_list.append(likelihoods[rxn])\n",
    "            rxns_w_likes.append(rxn)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihoods['rxn10481_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.remove_reactions(gaps_to_fill[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.solver = 'gurobi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pFBA with new media components (RNA bases + thymidine...)\n",
    "\n",
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "# Ensure free water exhange\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources + rna_bases\n",
    "set_media(model, media_list, universal, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop')\n",
    "# for aa_list in aas[0:1]:\n",
    "\n",
    "sys.stdout.write('\\n'+ str(counter))\n",
    "# aa = aa_list[1]+'_c'\n",
    "aa = 'cpd00117_c'\n",
    "# Add Demand Reaction for metabolite\n",
    "metabolite = model.metabolites.get_by_id(aa)\n",
    "demand = model.add_boundary(metabolite, type='demand')\n",
    "model.objective = demand\n",
    "# Gapfill\n",
    "sys.stdout.write('...gapfilling...')\n",
    "gaps_to_fill = gapfill(model, universal, demand_reactions=False) # Update to probannopy gapfill function; use Gurobi\n",
    "# Fill the gaps\n",
    "rxns_to_add = []\n",
    "for gap in gaps_to_fill:\n",
    "    model.add_reactions(gap)\n",
    "# Optimize with full pathway\n",
    "sys.stdout.write('optimizing...')\n",
    "solution = pfba(model, objective = demand)\n",
    "# Find reactions that carry flux\n",
    "df = solution.fluxes.to_frame()\n",
    "active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "# Add demand reactions for all metabolites, not used for optimization, simply there to stop blocked reactions\n",
    "all_mets = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "#         print(rxn)\n",
    "        rxn_obj = model.reactions.get_by_id(rxn)\n",
    "        for met in rxn_obj.metabolites:\n",
    "            if (met.id.endswith('_c')) & (met.id != aa):\n",
    "                all_mets.append(met.id)\n",
    "all_mets = set(all_mets)\n",
    "all_mets\n",
    "\n",
    "for met in all_mets:\n",
    "    metabolite = model.metabolites.get_by_id(met)\n",
    "    model.add_boundary(metabolite, type='demand')\n",
    "\n",
    "# Optimize again with new model with additional demands for active metabolites\n",
    "sys.stdout.write('optimizing_2...')\n",
    "solution = pfba(model, objective = demand)\n",
    "# Find reactions that carry flux\n",
    "df = solution.fluxes.to_frame()\n",
    "active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "\n",
    "# Acquire likelihood scores for reactions that carry flux\n",
    "like_list = []\n",
    "rxns_w_likes = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            like_list.append(likelihoods[rxn])\n",
    "            rxns_w_likes.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "avg_like = np.mean(like_list)\n",
    "sys.stdout.write('Average Likelihood of: ' + aa + ' is ' + str(avg_like)) # Change back to aa_list[1]\n",
    "aa_like[aa] = avg_like # Change back to aa_list[1]\n",
    "# Remove aa demand, filled gaps, and all other demands added to allow for free flowing flux\n",
    "model.remove_reactions([demand])\n",
    "model.remove_reactions(gaps_to_fill[0]) # This might not work when multiple reactions are added... \n",
    "\n",
    "for met in all_mets:\n",
    "    try:\n",
    "        model.remove_reactions([model.reactions.get_by_id('DM_'+met)])\n",
    "    except:\n",
    "        print('skipped')\n",
    "        print(met)\n",
    "\n",
    "counter += 1\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete:\" + str(elapsed/60) + \"mins\")\n",
    "print('\\n')\n",
    "print(gaps_to_fill)\n",
    "print(rxns_w_likes)\n",
    "print(like_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pFBA with new media components (RNA bases + thymidine...) \n",
    "# Remove reaction likelihoods of zero from model\n",
    "\n",
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "sys.stdout.write('Loading in models...')\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "sys.stdout.write('Adding Water...')\n",
    "\n",
    "# Ensure free water exchange\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "sys.stdout.write('Adjusting models...')\n",
    "\n",
    "# Remove all reactions with zero likelihood and insert them into universal with GPRs\n",
    "rxn_ids = [reaction.id for reaction in model.reactions]\n",
    "rxn_id_zero_like = []\n",
    "for rxn in rxn_ids:\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            if likelihoods[rxn] == 0.0:\n",
    "                rxn_id_zero_like.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "rxn_objs = []\n",
    "for rxn in rxn_id_zero_like:\n",
    "    rxn_objs.append(model.reactions.get_by_id(rxn))\n",
    "    \n",
    "model.remove_reactions(rxn_objs)\n",
    "universal.remove_reactions(rxn_id_zero_like)\n",
    "universal.add_reactions(rxn_objs)\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources + rna_bases\n",
    "set_media(model, media_list, universal, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop...')\n",
    "# for aa_list in aas[0:1]:\n",
    "\n",
    "sys.stdout.write('\\n'+ str(counter))\n",
    "# aa = aa_list[1]+'_c'\n",
    "aa = 'cpd00117_c'\n",
    "# Add Demand Reaction for metabolite\n",
    "metabolite = model.metabolites.get_by_id(aa)\n",
    "demand = model.add_boundary(metabolite, type='demand')\n",
    "model.objective = demand\n",
    "\n",
    "# Gapfill\n",
    "sys.stdout.write('Gapfilling...')\n",
    "gaps_to_fill = gapfill(model, universal, demand_reactions=False) # Update to probannopy gapfill function; use Gurobi\n",
    "# Fill the gaps\n",
    "rxns_to_add = []\n",
    "for gap in gaps_to_fill:\n",
    "    model.add_reactions(gap)\n",
    "# Optimize with full pathway\n",
    "sys.stdout.write('Optimizing...')\n",
    "solution = pfba(model, objective = demand)\n",
    "# Find reactions that carry flux\n",
    "df = solution.fluxes.to_frame()\n",
    "active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "# Add demand reactions for all metabolites, not used for optimization, simply there to stop blocked reactions\n",
    "all_mets = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "#         print(rxn)\n",
    "        rxn_obj = model.reactions.get_by_id(rxn)\n",
    "        for met in rxn_obj.metabolites:\n",
    "            if (met.id.endswith('_c')) & (met.id != aa):\n",
    "                all_mets.append(met.id)\n",
    "all_mets = set(all_mets)\n",
    "all_mets\n",
    "\n",
    "for met in all_mets:\n",
    "    metabolite = model.metabolites.get_by_id(met)\n",
    "    model.add_boundary(metabolite, type='demand')\n",
    "\n",
    "# Optimize again with new model with additional demands for active metabolites\n",
    "sys.stdout.write('Optimizing Again...')\n",
    "solution = pfba(model, objective = demand)\n",
    "# Find reactions that carry flux\n",
    "df = solution.fluxes.to_frame()\n",
    "active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "\n",
    "# Acquire likelihood scores for reactions that carry flux\n",
    "like_list = []\n",
    "rxns_w_likes = []\n",
    "for rxn in list(active.index):\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            like_list.append(likelihoods[rxn])\n",
    "            rxns_w_likes.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "avg_like = np.mean(like_list)\n",
    "sys.stdout.write('Average Likelihood of: ' + aa + ' is ' + str(avg_like)) # Change back to aa_list[1]\n",
    "aa_like[aa] = avg_like # Change back to aa_list[1]\n",
    "# Remove aa demand, filled gaps, and all other demands added to allow for free flowing flux\n",
    "model.remove_reactions([demand])\n",
    "model.remove_reactions(gaps_to_fill[0]) # This might not work when multiple reactions are added... \n",
    "\n",
    "for met in all_mets:\n",
    "    try:\n",
    "        model.remove_reactions([model.reactions.get_by_id('DM_'+met)])\n",
    "    except:\n",
    "        print('skipped')\n",
    "        print(met)\n",
    "\n",
    "counter += 1\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete:\" + str(elapsed/60) + \"mins\")\n",
    "print('\\n')\n",
    "print(gaps_to_fill)\n",
    "print(rxns_w_likes)\n",
    "print(like_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move forward even though copper transporters are back in the list; probannopy might fix this issue.\n",
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pFBA with new media components (RNA bases + thymidine...) \n",
    "# Remove reaction likelihoods of zero from model\n",
    "# Add demands for all metabolites in model to avoid any reactions being blocked\n",
    "\n",
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "sys.stdout.write('Loading in models...')\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "sys.stdout.write('Adding Water...')\n",
    "\n",
    "# Ensure free diffusion of water\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "sys.stdout.write('Adjusting models...')\n",
    "\n",
    "# Remove all reactions with less than 0.1 likelihood and insert them into universal with GPRs\n",
    "rxn_ids = [reaction.id for reaction in model.reactions]\n",
    "rxn_id_zero_like = []\n",
    "for rxn in rxn_ids:\n",
    "    if rxn.startswith('rxn'):\n",
    "        try:\n",
    "            if likelihoods[rxn] < 0.1:\n",
    "                rxn_id_zero_like.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "rxn_objs = []\n",
    "for rxn in rxn_id_zero_like:\n",
    "    rxn_objs.append(model.reactions.get_by_id(rxn))\n",
    "\n",
    "model.remove_reactions(rxn_objs)\n",
    "universal.remove_reactions(rxn_id_zero_like)\n",
    "universal.add_reactions(rxn_objs)\n",
    "\n",
    "# Add GPRs from likelihood dict to universal reactions that are still missing them\n",
    "rxn_ids = [reaction.id for reaction in universal.reactions]\n",
    "rxns_to_fix = []\n",
    "for rxn in rxn_ids:\n",
    "    if rxn.startswith('rxn'):\n",
    "        try: # This catches all of the reactions that have no likelihood value.\n",
    "            if likelihoods[rxn] > 0.0:\n",
    "                if universal.reactions.get_by_id(rxn).gene_reaction_rule == '':\n",
    "                    if likelihoods.data[rxn]['gpr'] != '':\n",
    "                        rxns_to_fix.append(rxn)\n",
    "                        universal.reactions.get_by_id(rxn).gene_reaction_rule = likelihoods.data[rxn]['gpr']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Add demand for all metabolites in Universal model to stop blocked reactions\n",
    "all_mets = []\n",
    "for met in universal.metabolites:\n",
    "    if (met.id.endswith('_c')): # & (met.id != aa):\n",
    "        model.add_boundary(met, type='demand')\n",
    "\n",
    "total_dataset_dict = {}\n",
    "carb_idx = 0\n",
    "nit_idx = 0\n",
    "product_idx = 0\n",
    "carbon = 'D-Glucose'\n",
    "nitrogen = 'NH3'\n",
    "        \n",
    "### Double For loop to set media\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources + rna_bases # + nitrogen + carbon\n",
    "set_media(model, media_list, universal, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop...')\n",
    "for aa_list in aas[0:10]:\n",
    "\n",
    "    sys.stdout.write('\\n'+ 'Loop' + str(counter) + ' ')\n",
    "    aa = aa_list[1]+'_c'\n",
    "    product_idx += 1 #Keep track to which product is being maximized\n",
    "    product = aa_list[0]\n",
    "    # aa = 'cpd00117_c'\n",
    "\n",
    "    # Add Demand Reaction for metabolite of interest and set to be objective\n",
    "    demand = model.reactions.get_by_id('DM_'+ aa) # demand\n",
    "    model.objective = demand\n",
    "\n",
    "    # Gapfill with probanno\n",
    "    sys.stdout.write('Gapfilling...')\n",
    "    # model.solver = 'gurobi'\n",
    "    # gaps_to_fill = probabilistic_gapfill(model, universal, likelihoods, dm_rxns=False, ex_rxns=False)\n",
    "    gaps_to_fill = gapfill(model, universal, demand_reactions=False) # Update to probannopy gapfill function; use Gurobi\n",
    "    # Fill the gaps\n",
    "    rxns_to_add = []\n",
    "    for gap in gaps_to_fill:\n",
    "        model.add_reactions(gap)\n",
    "\n",
    "    # Optimize with full pathway\n",
    "    sys.stdout.write('Optimizing...')\n",
    "    solution = pfba(model, objective = demand)\n",
    "    # Find reactions that carry flux\n",
    "    df = solution.fluxes.to_frame()\n",
    "    active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "    \n",
    "    # Acquire likelihood scores for reactions that carry flux\n",
    "    flux_rxns = []\n",
    "    like_list = []\n",
    "    for rxn in list(active.index):\n",
    "        if rxn.startswith('rxn'):\n",
    "            try:\n",
    "                flux_rxns.append([str(rxn),likelihoods[str(rxn)]])\n",
    "                like_list.append(likelihoods[str(rxn)])\n",
    "            except:\n",
    "                pass\n",
    "    avg_like = np.mean(like_list)\n",
    "    sys.stdout.write('Ave likelihood of: ' + aa_list[1] + ' is ' + str(avg_like)) \n",
    "#     aa_like[aa] = avg_like # Change back to aa_list[1]\n",
    "    # Remove aa demand, filled gaps\n",
    "    model.remove_reactions([demand])\n",
    "    model.remove_reactions(gaps_to_fill[0]) # This might not work when multiple reactions are added... \n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    report_dict = {}\n",
    "\n",
    "    report_dict['Model_ID'] = genome_id\n",
    "    report_dict['Carbon'] = carbon\n",
    "    report_dict['Nitrogen'] = nitrogen\n",
    "    report_dict['objective'] = product\n",
    "    report_dict['avg_path_like'] = avg_like\n",
    "    report_dict['gaps_filled'] = gaps_to_fill[0]\n",
    "    report_dict['reactions_w_flux'] = flux_rxns\n",
    "    report_dict['active_rxns'] = active\n",
    "    \n",
    "    report_dict_ID = genome_id + ':' + str(carb_idx) + '.' + str(nit_idx) + '.' + str(product_idx)\n",
    "    total_dataset_dict[report_dict_ID] = report_dict\n",
    "    \n",
    "    elapsed = time.time() - t\n",
    "    sys.stdout.write('Run time: ' + str(elapsed/60) + \" [mins]\")\n",
    "\n",
    "file_name = \"../metabolic_output/%s.data\" % (genome_id)\n",
    "pickle.dump(total_dataset_dict, open(file_name, \"wb\"))\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete: \" + str(elapsed/60) + \" [mins]\")\n",
    "# print('\\n')\n",
    "# print(gaps_to_fill)\n",
    "# # print(rxns_w_likes)\n",
    "# # print(like_list)\n",
    "# print(flux_rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = {}\n",
    "\n",
    "report_dict['Model_ID'] = genome_id\n",
    "report_dict['Carbon'] = nitrogen\n",
    "report_dict['Nitrogen'] = carbon\n",
    "report_dict['objective'] = aa\n",
    "report_dict['avg_path_like'] = avg_like\n",
    "report_dict['gaps_filled'] = gaps_to_fill[0]\n",
    "report_dict['reactions_w_flux'] = flux_rxns\n",
    "report_dict['active_rxns'] = active\n",
    "\n",
    "total_dataset_dict = {}\n",
    "\n",
    "i = 1\n",
    "j = 1\n",
    "k = 1\n",
    "\n",
    "total_dataset_dict[genome_id + ':' + str(i) + '.' + str(j) + '.' + str(k)] = report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for met in all_mets:\n",
    "#     try:\n",
    "#         model.remove_reactions([model.reactions.get_by_id('DM_'+met)])\n",
    "#     except:\n",
    "#         print('skipped')\n",
    "#         print(met)\n",
    "\n",
    "# Spontaneous diffusion based reactions\n",
    "# diff_rxns = findDiffusionRxns(universal)\n",
    "\n",
    "# Add dummy GPRs to rest of the reactions that should have genes so pFBA treats them all the same.\n",
    "# rxns_with_tempGPR = []\n",
    "# for rxn in universal.reactions:\n",
    "#     if rxn.id.startswith('rxn') and rxn.id not in diff_rxns and rxn.gene_reaction_rule == '':\n",
    "#         universal.reactions.get_by_id(rxn.id).gene_reaction_rule = 'Temp_GPR'\n",
    "#         rxns_with_tempGPR.append(rxn.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very fast and efficient gap filling function\n",
    "def iterative_pFBA_GapFill(model, bag, tasks=None, task_lb=0.01, obj=None, iters=100, add_exchanges=True, extracellular='Extracellular'):\n",
    "    '''\n",
    "    Function that utilizes iterations of pFBA solution with a universal reaction bag \n",
    "    in order to gapfill a model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : cobra.Model\n",
    "        Model to be gapfilled\n",
    "    bag : cobra.Model\n",
    "        Reaction bag to gapfill from\n",
    "    obj : string\n",
    "        Reaction ID for objective function in model to be gapfilled.\n",
    "    tasks : list or None\n",
    "        List of reactions IDs (strings) of metabolic tasks \n",
    "        to set a minimum lower bound for. \n",
    "    lb : float\n",
    "        Lower bound for objective and any metabolic tasks\n",
    "    iters : int\n",
    "        Number of gapfilling rounds. Unique reactions from each round are \n",
    "        saved and the union is added simulatneously to the model.\n",
    "    add_exchanges : bool\n",
    "        Identifies extracellular metabolites added during gapfilling that\n",
    "        are not associated with exchange reactions and creates them\n",
    "    extracellular : string\n",
    "        Label for extracellular compartment of model\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Save some basic network info for downstream membership testing\n",
    "    orig_rxns = list(copy.deepcopy(model.reactions))\n",
    "    orig_rxn_ids = set([str(x.id) for x in model.reactions])\n",
    "    orig_cpd_ids = set([str(y.id) for y in model.metabolites])\n",
    "    univ_rnx_ids = set([str(z.id) for z in bag.reactions])\n",
    "    \n",
    "    # Find overlap in model and reaction bag\n",
    "    overlap_rxn_ids = univ_rnx_ids.intersection(orig_rxn_ids)\n",
    "    \n",
    "    # Get model objective reaction ID\n",
    "    if obj == None:\n",
    "        obj = get_objective(model)\n",
    "    else:\n",
    "        obj = obj\n",
    "    \n",
    "    # Modify universal reaction bag\n",
    "    new_rxn_ids = set()\n",
    "    with bag as universal:\n",
    "\n",
    "        # Remove overlapping reactions from universal bag, and reset objective if needed\n",
    "        for rxn in overlap_rxn_ids: \n",
    "            universal.reactions.get_by_id(rxn).remove_from_model()\n",
    "    \n",
    "        # Add pFBA to universal model and add model reactions\n",
    "        add_pfba(universal)\n",
    "        universal.add_reactions(orig_rxns)\n",
    "        universal.reactions.get_by_id(obj).lower_bound = task_lb\n",
    "    \n",
    "        # Set metabolic tasks that must carry flux in gapfilled solution\n",
    "        if tasks != None:\n",
    "            for task in tasks:                    \n",
    "                universal.reactions.get_by_id(task).lower_bound = task_lb\n",
    "                \n",
    "        # Optimize and run flux sampling\n",
    "        universal = copy.deepcopy(universal) # reset solver\n",
    "        solution = universal.optimize()\n",
    "        print('Sampling ' + str(iters) + ' flux distributions...')\n",
    "        flux_samples = sample(universal, iters)\n",
    "        rnxs = list(flux_samples.columns)\n",
    "         \n",
    "        # Assess the sampled flux distributions\n",
    "        for distribution in flux_samples.iterrows():\n",
    "            for flux in range(0, len(list(distribution[1]))):\n",
    "                if list(distribution[1])[flux] > 1e-6: \n",
    "                    new_rxn_ids |= set([rnxs[flux]]).difference(orig_rxn_ids)\n",
    "    \n",
    "    # Get reactions and metabolites to be added to the model\n",
    "    new_rxns = copy.deepcopy([bag.reactions.get_by_id(rxn) for rxn in new_rxn_ids])\n",
    "    new_cpd_ids = set()\n",
    "    for rxn in new_rxns: new_cpd_ids |= set([str(x.id) for x in list(rxn.metabolites)])\n",
    "    new_cpd_ids = new_cpd_ids.difference(orig_cpd_ids)\n",
    "    new_cpds = copy.deepcopy([bag.reactions.get_by_id(cpd) for rxn in new_cpd_ids])\n",
    "    \n",
    "    # Copy model and gapfill \n",
    "    new_model = copy.deepcopy(model)\n",
    "    new_model.add_metabolites(new_cpds)\n",
    "    new_model.add_reactions(new_rxns)\n",
    "    \n",
    "#     # Identify extracellular metabolites with no exchanges\n",
    "#     if add_exchanges == True:\n",
    "#         new_exchanges = extend_exchanges(new_model, new_cpd_ids, extracellular)\n",
    "#         if len(new_exchanges) > 0: \n",
    "#             print('Identified and filled ' + str(len(new_exchanges)) + ' missing exchange reactions.')\n",
    "#             new_rxn_ids |= new_exchanges\n",
    "    \n",
    "#     duration = int(round(time.time() - start_time))\n",
    "#     print('Took ' + str(duration) + ' seconds to gapfill ' + str(len(new_rxn_ids)) + ' reactions and ' + str(len(new_cpd_ids)) + ' metabolites.') \n",
    "    \n",
    "    return new_model, new_rxn_ids\n",
    "\n",
    "\n",
    "# # Adds missing exchanges for extracellulart metbaolites\n",
    "# def extend_exchanges(model, cpd_ids, ex):\n",
    "    \n",
    "#     model_exchanges = set(find_boundary_types(model, 'exchange', external_compartment=ex))\n",
    "#     new_ex_ids = set()\n",
    "    \n",
    "#     for cpd in cpd_ids:\n",
    "#         cpd = model.metabolites.get_by_id(cpd)\n",
    "#         if cpd.compartment != extracellular:\n",
    "#             continue\n",
    "#         else:\n",
    "#             if bool(set(cpd.reactions) & model_exchanges) == False:\n",
    "#                 try:\n",
    "#                     new_id = 'EX_' + cpd.id\n",
    "#                     model.add_boundary(cpd, type='exchange', reaction_id=new_id, lb=-1000.0, ub=1000.0)\n",
    "#                     new_ex_ids |= set([new_id])\n",
    "#                 except ValueError:\n",
    "#                     pass\n",
    "                \n",
    "#     return new_ex_ids\n",
    "\n",
    "\n",
    "# Returns the reaction ID of the objective reaction\n",
    "def get_objective(model):\n",
    "    \n",
    "    if len(list(model.objective.variables)) == 0:\n",
    "        raise IndexError('Model has no objective set.')\n",
    "    \n",
    "    expression = str(model.objective.expression).split()\n",
    "    if 'reverse' in expression[0]:\n",
    "        obj_id = expression[2].split('*')[-1]\n",
    "    else:\n",
    "        obj_id = expression[0].split('*')[-1]\n",
    "            \n",
    "    return obj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pFBA with new media components (RNA bases + thymidine...) \n",
    "# Remove reaction likelihoods of zero from model\n",
    "# Add demands for all metabolites in model to avoid any reactions being blocked\n",
    "# Use thresholded likelihoods to penalize reactions with no likelihood using pFBA gapfill\n",
    "\n",
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "sys.stdout.write('Loading in models...')\n",
    "\n",
    "universal_orig = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "universal = copy.deepcopy(universal_orig)\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "sys.stdout.write('Adding Water...')\n",
    "\n",
    "# Ensure free diffusion of water\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "sys.stdout.write('Removing Model Rxns...')\n",
    "# Add all model reactions to Universal model\n",
    "model_reactions = copy.deepcopy(model.reactions)\n",
    "model_reactions_to_remove = []\n",
    "for rxn in model.reactions:\n",
    "    if rxn.id in set([reaction.id for reaction in universal.reactions]):\n",
    "        model_reactions_to_remove.append(rxn)\n",
    "universal.remove_reactions([reaction.id for reaction in model_reactions_to_remove])\n",
    "universal.add_reactions(model_reactions)\n",
    "\n",
    "sys.stdout.write('Add Demands...')\n",
    "# Add demand for all metabolites in Universal model to stop blocked reactions\n",
    "all_mets = []\n",
    "for met in universal.metabolites:\n",
    "    if (met.id.endswith('_c')):\n",
    "        universal.add_boundary(met, type='demand')\n",
    "\n",
    "sys.stdout.write('Add Missing GPRs...')\n",
    "# Add GPRs from likelihood dict to universal reactions that are still missing them\n",
    "rxn_ids = [reaction.id for reaction in universal.reactions]\n",
    "rxns_to_fix = []\n",
    "for rxn in rxn_ids:\n",
    "    if rxn.startswith('rxn'):\n",
    "        try: # This catches all of the reactions that have no likelihood value.\n",
    "            if likelihoods[rxn] > 0.0:\n",
    "                if universal.reactions.get_by_id(rxn).gene_reaction_rule == '':\n",
    "                    if likelihoods.data[rxn]['gpr'] != '':\n",
    "                        rxns_to_fix.append(rxn)\n",
    "                        universal.reactions.get_by_id(rxn).gene_reaction_rule = likelihoods.data[rxn]['gpr']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "sys.stdout.write('Remove High Likelihood rxns...')\n",
    "# Remove reactions that have greater than 0.1 likelihood from universal\n",
    "rxns_w_like = []\n",
    "for rxn in universal.reactions:\n",
    "    if rxn.id.startswith('rxn'):\n",
    "        try:\n",
    "            if likelihoods[rxn.id] >= 0.1:\n",
    "                rxns_w_like.append(rxn)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# rxns_w_like = copy.deepcopy(rxns_w_like)\n",
    "universal.remove_reactions(rxns_w_like)\n",
    "\n",
    "sys.stdout.write('Add pFBA...')\n",
    "# Add pFBA to universal model\n",
    "add_pfba(universal)\n",
    "\n",
    "# Add likely reactions back into Universal so their flux is not minimized\n",
    "universal.add_reactions(rxns_w_like)\n",
    "\n",
    "total_dataset_dict = {}\n",
    "carb_idx = 0\n",
    "nit_idx = 0\n",
    "product_idx = 0\n",
    "carbon = 'D-Glucose'\n",
    "nitrogen = 'NH3'\n",
    "\n",
    "### Double For-loop to set media\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources + rna_bases # + nitrogen + carbon\n",
    "set_media(universal, media_list, universal_orig, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop...')\n",
    "for aa_list in aas[0:10]:\n",
    "\n",
    "    sys.stdout.write('\\n'+ 'Loop' + str(counter) + ' ')\n",
    "    aa = aa_list[1]+'_c'\n",
    "    product = aa_list[0]\n",
    "\n",
    "    task_lb = 100\n",
    "    obj = 'DM_'+ aa\n",
    "    universal.reactions.get_by_id(obj).lower_bound = task_lb\n",
    "\n",
    "    # Optimize and run flux sampling\n",
    "    sys.stdout.write('Optimizing...')\n",
    "    solution = universal.optimize()\n",
    "\n",
    "    # Reset Objective lower bound for next loop\n",
    "    universal.reactions.get_by_id(obj).lower_bound = 0.0\n",
    "\n",
    "    # Optimize with full pathway\n",
    "    sys.stdout.write('Constructing Dict...')\n",
    "    # Find reactions that carry flux\n",
    "    df = solution.fluxes.to_frame()\n",
    "    active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "\n",
    "    # Acquire likelihood scores for reactions that carry flux\n",
    "    flux_rxns = []\n",
    "    like_list = []\n",
    "    for rxn in list(active.index):\n",
    "        if rxn.startswith('rxn'):\n",
    "            try:\n",
    "                flux_rxns.append([str(rxn),likelihoods[str(rxn)]])\n",
    "                like_list.append(likelihoods[str(rxn)])\n",
    "            except:\n",
    "                pass\n",
    "    avg_like = np.mean(like_list)\n",
    "    sys.stdout.write('Ave likelihood of: ' + aa + ' is ' + str(avg_like)) \n",
    "#     aa_like[aa] = avg_like # Change back to aa_list[1]\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    report_dict = {}\n",
    "\n",
    "    report_dict['Model_ID'] = genome_id\n",
    "    report_dict['Carbon'] = carbon\n",
    "    report_dict['Nitrogen'] = nitrogen\n",
    "    report_dict['objective'] = product\n",
    "    report_dict['avg_path_like'] = avg_like\n",
    "#     report_dict['gaps_filled'] = gaps_to_fill[0]\n",
    "    report_dict['reactions_w_flux'] = flux_rxns\n",
    "    report_dict['active_rxns'] = active\n",
    "\n",
    "    report_dict_ID = genome_id + ':' + str(carb_idx) + '.' + str(nit_idx) + '.' + str(product_idx)\n",
    "    total_dataset_dict[report_dict_ID] = report_dict\n",
    "    product_idx += 1 #Keep track to which product is being maximized\n",
    "\n",
    "    elapsed = time.time() - t\n",
    "    sys.stdout.write('Run time: ' + str(elapsed/60) + \" [mins]\")\n",
    "\n",
    "file_name = \"../metabolic_output/%s.data\" % (genome_id)\n",
    "pickle.dump(total_dataset_dict, open(file_name, \"wb\"))\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete: \" + str(elapsed/60) + \" [mins]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns_w_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal.objective.expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from cobra.core.model import copy\n",
    "\n",
    "def probabilistic_gapfill(model, universal_model, reaction_probabilities, clean_exchange_rxns=True, default_penalties=None, dm_rxns=False, ex_rxns=False, **solver_parameters):\n",
    "    \"\"\"\n",
    "    Gapfill a model using probabilistic weights\n",
    "    :param default_penalties:\n",
    "    :param model: cobra Model object, the model to be gapfilled\n",
    "    :param universal_model: cobra Model object representing the database of reactions to choose from\n",
    "    :param reaction_probabilities: reaction_probabilities dictionary\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    universal_model = universal_model.copy()\n",
    "    model = clean_exchange_reactions(model) if clean_exchange_rxns else model.copy()\n",
    "    if default_penalties is None:\n",
    "        default_penalties = {'Universal': 1, 'Exchange': 100, 'Demand': 1, 'Reverse': 75}\n",
    "    penalties = default_penalties\n",
    "    reactions_to_remove = []\n",
    "    for r in universal_model.reactions:\n",
    "        if model.reactions.has_id(r.id):\n",
    "            reactions_to_remove.append(r)\n",
    "            penalties[r.id] = 0  # In the model\n",
    "        elif r.id in reaction_probabilities:\n",
    "            penalties[r.id] = max(0, 1 - reaction_probabilities[r.id]) * (penalties[r.id] if r.id in penalties else 1)\n",
    "    universal_model.remove_reactions(reactions_to_remove)\n",
    "    return cobra.flux_analysis.gapfill(model, universal_model, penalties=penalties, demand_reactions=dm_rxns, exchange_reactions=ex_rxns, **solver_parameters)\n",
    "\n",
    "\n",
    "def clean_exchange_reactions(model, regex='.*_e([0-9]*)$'):\n",
    "    model = model.copy()\n",
    "    compound_regex = re.compile(regex)\n",
    "    mets_to_clean = [m for m in model.metabolites if compound_regex.match(m.id)]\n",
    "    for m in mets_to_clean:\n",
    "        m.remove_from_model()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pFBA with new media components (RNA bases + thymidine...) \n",
    "# Remove reaction likelihoods of zero from model\n",
    "# Add demands for all metabolites in model to avoid any reactions being blocked\n",
    "# Use thresholded likelihoods to penalize reactions with no likelihood using pFBA gapfill\n",
    "# Use pFBA answer + 0 likelihood reactions from reconstructed model + higher likelihood reactions to probanno gapfill\n",
    "\n",
    "t = time.time()\n",
    "counter = 0\n",
    "\n",
    "sys.stdout.write('Loading in models...')\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "sys.stdout.write('Adding Water...')\n",
    "\n",
    "# Ensure free diffusion of water\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "sys.stdout.write('Set-up Universal...')\n",
    "\n",
    "### Set up Universal\n",
    "# Add all model reactions to Universal model\n",
    "model_reactions = copy.deepcopy(model.reactions)\n",
    "model_reactions_to_remove = []\n",
    "for rxn in model.reactions:\n",
    "    if rxn.id in set([reaction.id for reaction in universal.reactions]):\n",
    "        model_reactions_to_remove.append(rxn)\n",
    "universal.remove_reactions([reaction.id for reaction in model_reactions_to_remove])\n",
    "universal.add_reactions(model_reactions)\n",
    "\n",
    "# Add GPRs from likelihood dict to universal reactions that are still missing them\n",
    "rxn_ids = [reaction.id for reaction in universal.reactions]\n",
    "rxns_to_fix = []\n",
    "for rxn in rxn_ids:\n",
    "    if rxn.startswith('rxn'):\n",
    "        try: # This catches all of the reactions that have no likelihood value.\n",
    "            if likelihoods[rxn] > 0.0:\n",
    "                if universal.reactions.get_by_id(rxn).gene_reaction_rule == '':\n",
    "                    if likelihoods.data[rxn]['gpr'] != '':\n",
    "                        rxns_to_fix.append(rxn)\n",
    "                        universal.reactions.get_by_id(rxn).gene_reaction_rule = likelihoods.data[rxn]['gpr']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Add demand for all metabolites in Universal model to stop blocked reactions\n",
    "all_mets = []\n",
    "for met in universal.metabolites:\n",
    "    if (met.id.endswith('_c')):\n",
    "        universal.add_boundary(met, type='demand')\n",
    "\n",
    "### Set Up Model: remove low likelihood reactions\n",
    "sys.stdout.write('Set-up Model...')\n",
    "low_like_model = []\n",
    "for rxn in model.reactions:\n",
    "    if rxn.id.startswith('rxn'):\n",
    "        try:\n",
    "            if likelihoods[rxn.id] <= 0.1:\n",
    "                low_like_model.append(rxn.id)\n",
    "        except:\n",
    "            pass\n",
    "model_rxns_to_remove = [model.reactions.get_by_id(rxn) for rxn in low_like_model]\n",
    "model.remove_reactions(model_rxns_to_remove)\n",
    "\n",
    "### Set Up Bag: Leave only low-likelihood-model reactions, and high-likelihood-non-model reactions for now\n",
    "sys.stdout.write('Set-up Bag...')\n",
    "\n",
    "# Make deepcopy of universal for bag to process later\n",
    "bag = copy.deepcopy(universal)\n",
    "\n",
    "# Find reaction IDs for the high-likelihood reactions only in the universal model\n",
    "high_like_non_model = []\n",
    "for rxn in universal.reactions:\n",
    "    if rxn.id.startswith('rxn') and rxn.id not in [reaction.id for reaction in model.reactions]:\n",
    "        try:\n",
    "            if likelihoods[rxn.id] >= 0.1:\n",
    "                high_like_non_model.append(rxn.id)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "uni_rxn_ids = [reaction.id for reaction in universal.reactions]\n",
    "rxns_to_remove = set(uni_rxn_ids).difference(set(high_like_non_model).union(set(low_like_model)))\n",
    "\n",
    "sys.stdout.write('Trimming Bag...')\n",
    "bag.remove_reactions([bag.reactions.get_by_id(rxn) for rxn in rxns_to_remove])\n",
    "\n",
    "# Save Models\n",
    "sys.stdout.write('Saving...')\n",
    "cobra.io.save_json_model(universal, \"universal.json\")\n",
    "cobra.io.save_json_model(model, \"model.json\")\n",
    "cobra.io.save_json_model(bag, \"bag.json\")\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete: \" + str(elapsed/60) + \" [mins]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models...Starting Loop...\n",
      "Loop0 Optimizing...1000.0...Add to bag...Add demand to model...Gapfilling...pFBA...1000.0...Constructing Dict...Ave likelihood of: cpd00117_c is 0.4601774975211276Resetting...Run time: 0.43443018198 [mins]\n",
      "Loop1 Optimizing...1000.0...Add to bag...Add demand to model...Gapfilling..."
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "sys.stdout.write('Loading Models...')\n",
    "universal = cobra.io.load_json_model('universal.json')\n",
    "model = cobra.io.load_json_model('model.json')\n",
    "bag = cobra.io.load_json_model('bag.json')\n",
    "genome_id = '220668.9'\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "total_dataset_dict = {}\n",
    "carb_idx = 0\n",
    "nit_idx = 0\n",
    "product_idx = 0\n",
    "carbon = 'D-Glucose'\n",
    "nitrogen = 'NH3'\n",
    "\n",
    "### Double For-loop to set media\n",
    "\n",
    "# Create specific Media List\n",
    "media_list = bsm + M9_sources + rna_bases # + nitrogen + carbon\n",
    "set_media(model, media_list, universal, verbose=False)\n",
    "set_media(universal, media_list, universal, verbose=False)\n",
    "\n",
    "# Run through each amino acid to check for production\n",
    "aa_like = {}\n",
    "sys.stdout.write('Starting Loop...')\n",
    "for aa_list in aas[0:10]:\n",
    "    \n",
    "    sys.stdout.write('\\n'+ 'Loop' + str(counter) + ' ')\n",
    "    aa = aa_list[1]+'_c'\n",
    "    product = aa_list[0]\n",
    "    \n",
    "#     task_lb = 100\n",
    "    obj = 'DM_'+ aa\n",
    "    universal.objective = universal.reactions.get_by_id(obj)\n",
    "    \n",
    "    # Optimize universal with FBA to get possible reactions\n",
    "    sys.stdout.write('Optimizing...')\n",
    "    solution = universal.optimize()\n",
    "    sys.stdout.write(str(round(universal.slim_optimize())) + '...')\n",
    "    df = solution.fluxes.to_frame()\n",
    "    active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "    \n",
    "    # Add solution space to bag\n",
    "    sys.stdout.write('Add to bag...')\n",
    "    rxns_to_add_to_bag = []\n",
    "    for rxn in active.index:\n",
    "        if rxn not in [reaction.id for reaction in bag.reactions]:\n",
    "            rxns_to_add_to_bag.append(universal.reactions.get_by_id(rxn))\n",
    "    rxns_to_add_to_bag_copy = deepcopy(rxns_to_add_to_bag)\n",
    "    \n",
    "    bag.add_reactions(rxns_to_add_to_bag_copy)\n",
    "    \n",
    "    sys.stdout.write('Bag size'+ len(bag.reactions) +'...')\n",
    "\n",
    "    # Add Demand Reaction for metabolite of interest and set to be objective\n",
    "    sys.stdout.write('Add demand to model...')\n",
    "    if aa not in [met.id for met in model.metabolites]:\n",
    "        metabolite = deepcopy(universal.metabolite.get_by_id(aa))\n",
    "        model.add_metabolites([metabolite])\n",
    "    else:\n",
    "        metabolite = model.metabolites.get_by_id(aa)\n",
    "    demand = model.add_boundary(metabolite, type='demand')\n",
    "#     model.add_reactions([demand])\n",
    "    model.objective = demand\n",
    "    \n",
    "    # Gapfill with probanno\n",
    "    sys.stdout.write('Gapfilling...')\n",
    "    # model.solver = 'gurobi'\n",
    "#     gaps_to_fill = probabilistic_gapfill(model, bag, likelihoods, dm_rxns=False, ex_rxns=False)\n",
    "#     gaps_to_fill = gapfill(model, bag, demand_reactions=False) # Update to probannopy gapfill function; use Gurobi\n",
    "    \n",
    "    with bag as bag:\n",
    "        default_penalties = {'Universal': 1, 'Exchange': 100, 'Demand': 1, 'Reverse': 75}\n",
    "        penalties = default_penalties\n",
    "        reactions_to_remove = []\n",
    "        for r in bag.reactions:\n",
    "            if model.reactions.has_id(r.id):\n",
    "                reactions_to_remove.append(r)\n",
    "                penalties[r.id] = 0  # In the model\n",
    "            elif r.id in likelihoods:\n",
    "                penalties[r.id] = max(0, 1 - likelihoods[r.id]) * (penalties[r.id] if r.id in penalties else 1)\n",
    "            else:\n",
    "                penalties[r.id] = 1\n",
    "        bag.remove_reactions(reactions_to_remove)\n",
    "        gaps_to_fill = gapfill(model, bag, penalties=penalties, demand_reactions=False)\n",
    "    \n",
    "    # Fill the gaps\n",
    "    rxns_to_add = []\n",
    "    for gap in gaps_to_fill:\n",
    "        model.add_reactions(gap)\n",
    "\n",
    "    # Optimize with filled pathway\n",
    "    sys.stdout.write('pFBA...')\n",
    "    solution = pfba(model, objective = demand)\n",
    "    sys.stdout.write(str(round(model.slim_optimize())) + '...')\n",
    "\n",
    "    sys.stdout.write('Constructing Dict...')\n",
    "    # Find reactions that carry flux\n",
    "    df = solution.fluxes.to_frame()\n",
    "    active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "\n",
    "    # Acquire likelihood scores for reactions that carry flux\n",
    "    flux_rxns = []\n",
    "    like_list = []\n",
    "    for rxn in list(active.index):\n",
    "        if rxn.startswith('rxn'):\n",
    "            try:\n",
    "                flux_rxns.append([str(rxn),likelihoods[str(rxn)]])\n",
    "                like_list.append(likelihoods[str(rxn)])\n",
    "            except:\n",
    "                pass\n",
    "    avg_like = np.mean(like_list)\n",
    "    sys.stdout.write('Ave likelihood of: ' + aa + ' is ' + str(avg_like)) \n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    report_dict = {}\n",
    "\n",
    "    report_dict['Model_ID'] = genome_id\n",
    "    report_dict['Carbon'] = carbon\n",
    "    report_dict['Nitrogen'] = nitrogen\n",
    "    report_dict['objective'] = product\n",
    "    report_dict['avg_path_like'] = avg_like\n",
    "    report_dict['gaps_filled'] = gaps_to_fill[0]\n",
    "    report_dict['reactions_w_flux'] = flux_rxns\n",
    "    report_dict['active_rxns'] = active\n",
    "\n",
    "    report_dict_ID = genome_id + ':' + str(carb_idx) + '.' + str(nit_idx) + '.' + str(product_idx)\n",
    "    total_dataset_dict[report_dict_ID] = report_dict\n",
    "    product_idx += 1 #Keep track to which product is being maximized\n",
    "\n",
    "    # Remove reactions to reset\n",
    "    sys.stdout.write('Resetting...')\n",
    "    model.remove_reactions([demand])\n",
    "    model.remove_reactions(gaps_to_fill[0])\n",
    "    bag.remove_reactions(rxns_to_add_to_bag_copy)\n",
    "    \n",
    "    elapsed = time.time() - t\n",
    "    sys.stdout.write('Run time: ' + str(elapsed/60) + \" [mins]\")\n",
    "\n",
    "file_name = \"../metabolic_output/%s.data\" % (genome_id)\n",
    "pickle.dump(total_dataset_dict, open(file_name, \"wb\"))\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(\"\\nTime to complete: \" + str(elapsed/60) + \" [mins]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
