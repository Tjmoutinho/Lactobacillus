{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import cobra\n",
    "import cobra.test\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from cobra.flux_analysis import sample\n",
    "from cobra.core.solution import get_solution\n",
    "from cobra.flux_analysis.sampling import OptGPSampler\n",
    "from cobra.manipulation.delete import *\n",
    "from cobra.medium import find_boundary_types\n",
    "from cobra.flux_analysis import pfba\n",
    "\n",
    "from warnings import warn\n",
    "from itertools import chain\n",
    "from optlang.symbolics import Zero\n",
    "from cobra.util import solver as sutil\n",
    "from cobra.core.solution import get_solution\n",
    "\n",
    "import logging\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "# Set default logger to python logger to avoid warnings given when adding reactions and/or metaboites \n",
    "# because \"cobra.core.model\" doesn't innately have a logger.\n",
    "# import logging\n",
    "# logging.basicConfig()\n",
    "# logger = logging.getLogger('logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_media(model, media, universal, verbose=False):\n",
    "\n",
    "    # Find and close all exchange reactions in the model\n",
    "    model_rxns = [rxn.id for rxn in model.reactions]\n",
    "    for rxn in model_rxns:\n",
    "        if rxn.startswith('EX_') and rxn.endswith('_e'):\n",
    "            model.reactions.get_by_id(rxn).lower_bound = 0.0\n",
    "\n",
    "    # Check for existence of exchange reactions for the media metabolites in the model\n",
    "    for metabolite in media:\n",
    "        met = metabolite[1]+'_e'\n",
    "        if 'EX_'+met in model_rxns:\n",
    "            model.reactions.get_by_id('EX_'+met).lower_bound = -1000.\n",
    "        else:\n",
    "            # Create exchange reaction and add to model\n",
    "            if verbose:\n",
    "                print(\"added exchange rxn for \" + met)\n",
    "            new_exchange = cobra.Reaction('EX_'+met)\n",
    "            new_exchange.name = met + ' exchange'\n",
    "            met_obj = universal.metabolites.get_by_id(met)\n",
    "            new_exchange.add_metabolites({met_obj:-1})\n",
    "            new_exchange.lower_bound = -1000.\n",
    "            new_exchange.upper_bound = 1000.\n",
    "            model.add_reaction(new_exchange)\n",
    "            model.repair()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basal Synthetic Media\n",
    "bsm = [\n",
    "    ['H+','cpd00067'],\n",
    "    ['H2O','cpd00001'],\n",
    "    ['CO2','cpd00011'],\n",
    "    ['O2','cpd00007'],\n",
    "    ['N2','cpd00528'], \n",
    "#     ['H2','cpd11640'], # Only with no O2\n",
    "    \n",
    "    ['K+','cpd00205'],\n",
    "    ['Na+','cpd00971'],\n",
    "    ['Mg','cpd00254'],\n",
    "    ['Mn2+','cpd00030'],\n",
    "    ['Fe2+','cpd10515'], # Iron ion in heme\n",
    "    ['Ca2+','cpd00063'], # Calcium pantothenate;cpd19112\n",
    "    \n",
    "    ['Vitamin B12r','cpd00423'], # C62H91CoN13O14P : cobalamin;cpd03424;cpd00730 : not present in any exchange reactions\n",
    "    ['Cobinamide','cpd03422'], #EXs : related to cobalamin (B12) Added to ensure cells have access to B12\n",
    "    ['BIOT','cpd00104'], # C10H15N2O3S : biotin B7\n",
    "    ['PAN','cpd00644'], # C9H16NO5 : Pantothenate B5\n",
    "    ['Folate','cpd00393'], # C19H17N7O6 : B9\n",
    "    ['Niacin','cpd00218'], # C6H4NO2 : B3\n",
    "    ['Pyridoxal','cpd00215'], # C8H9NO3 : B6\n",
    "    ['Riboflavin','cpd00220'], # C17H19N4O6 : B2\n",
    "    ['thiamin','cpd00305'], # C12H17N4OS : B1\n",
    "    \n",
    "#     ['Phosphate','cpd00009'], # HO4P : In M9 Defaults\n",
    "    \n",
    "    ['Thioglycolate','cpd01415'], # C2H3O2S : not present in any exchange reactions\n",
    "#     ['Sulfate','cpd00048'], # O4S : In M9 Defaults\n",
    "    \n",
    "    ['Acetate','cpd00029'], # C2H3O2 : not present in any exchange reactions\n",
    "    ['Citrate','cpd00137'], # C6H5O7 : Consider removing. \n",
    "#     ['Polysorbate 60','cpd24450'], # C35H68O10 : Almost tween 80 : not present in any reactions\n",
    "#     ['Ethyl acetate','cpd00633'], # C4H8O2 : not present in any exchange reactions, only present in one reaction at all\n",
    "    \n",
    "    ['ABEE','cpd00443'] # C7H6NO2 : aminobenzoate : not present in any exchange reactions\n",
    "]\n",
    "\n",
    "# Potentially add to BSM (from M9 media)\n",
    "M9_ions = [\n",
    "    ['Cl-','cpd00099'],\n",
    "    ['Co2+','cpd00149'],\n",
    "    ['Cu2+','cpd00058'],\n",
    "    ['Fe3','cpd10516'],\n",
    "#     ['Sodium molybdate','cpd11145'], # This doesn't connect to anything\n",
    "    ['Ni2+','cpd00244'],\n",
    "    ['Selenate','cpd03396'],\n",
    "    ['Selenite','cpd03387'],\n",
    "    ['Zn2+','cpd00034']\n",
    "]\n",
    "\n",
    "# M9 default carbon, nitrogen, phosphorous, and sulfur sources\n",
    "M9_sources = [\n",
    "#     ['D-Glucose','cpd00027'],\n",
    "#     ['NH3','cpd00013'], # this is actually NH4 : ammonium\n",
    "    ['Phosphate','cpd00009'],\n",
    "    ['Sulfate','cpd00048']\n",
    "]\n",
    "\n",
    "# Vitamins\n",
    "vit_k = [\n",
    "#     ['BIOT','cpd00104'], #EXs : Biotin\n",
    "#     ['Cobinamide','cpd03422'], #EXs : related to cobalamin (B12)\n",
    "#     ['Folate','cpd00393'], #EXs : \n",
    "    ['Menaquinone 7','cpd11606'], #EXs : Vitamine K2 : Add when there is no O2\n",
    "#     ['Niacin','cpd00218'], #EXs : \n",
    "#     ['PAN','cpd00644'], #EXs : Pantothenate\n",
    "#     ['Pyridoxal','cpd00215'], #EXs : \n",
    "#     ['Riboflavin','cpd00220'], #EXs : \n",
    "#     ['Thiamin','cpd00305'] #EXs : \n",
    "]\n",
    "\n",
    "# For aerobic simulations, O2 was added with a lower bound of âˆ’20 and to 0 for anaerobic simulations.\n",
    "\n",
    "# DNA/RNA related metabolites\n",
    "rna_bases = [\n",
    "#     ['35ccmp','cpd00696'], #EXs : \n",
    "#     ['AMP','cpd00018'], #EXs : \n",
    "    ['Adenosine','cpd00182'], #EXs : In BSM (as adenine)\n",
    "#     ['Adenosine 3-5-bisphosphate','cpd00045'], #EXs : \n",
    "    ['Cytosine','cpd00307'], #EXs : \n",
    "#     ['Deoxyadenosine','cpd00438'], #EXs : \n",
    "#     ['Deoxycytidine','cpd00654'], #EXs : \n",
    "#     ['Deoxyguanosine','cpd00277'], #EXs : In BSM\n",
    "#     ['Deoxyinosine','cpd03279'], #EXs : \n",
    "#     ['Deoxyuridine','cpd00412'], #EXs : \n",
    "#     ['GMP','cpd00126'], #EXs : \n",
    "#     ['GTP','cpd00038'], #EXs : \n",
    "    ['Guanosine','cpd00311'], #EXs : In BSM (as Guanine)\n",
    "#     ['Inosine','cpd00246'], #EXs : \n",
    "#     ['HYXN','cpd00226'], #EXs : Hypoxanthine\n",
    "#     ['Nicotinamide ribonucleotide','cpd00355'], #EXs : \n",
    "#     ['TTP','cpd00357'], #EXs : Deoxythymidine triphosphate\n",
    "    ['Thymidine','cpd00184'], #EXs : In BSM\n",
    "#     ['Thyminose','cpd01242'], #EXs : deoxyribose\n",
    "#     ['Uracil','cpd00092'], #EXs : \n",
    "    ['Uridine','cpd00249'], #EXs : In BSM (as uracil)\n",
    "#     ['XAN','cpd00309'], #EXs : Xanthine\n",
    "#     ['Xanthosine','cpd01217'], #EXs : \n",
    "#     ['dATP','cpd00115'], #EXs : \n",
    "#     ['dGTP','cpd00241'], #EXs : \n",
    "#     ['dTMP','cpd00298'] #EXs : \n",
    "]\n",
    "\n",
    "# Check to see if these metabolites are used in pathways? Should I add some of these to media? \n",
    "# Yes for ATP, and GTP. (TTP, CTP as well?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56hours\n"
     ]
    }
   ],
   "source": [
    "# Amino Acid related metabolites\n",
    "products = [\n",
    "    ['D-Alanine','cpd00117'], #EXs : \n",
    "    ['D-Glutamate','cpd00186'], #EXs : \n",
    "    ['D-Methionine','cpd00637'], #EXs : \n",
    "    ['D-Serine','cpd00550'], #EXs : \n",
    "    ['Glycine','cpd00033'], #EXs : 1\n",
    "    ['L-Alanine','cpd00035'], #EXs : 2\n",
    "    ['L-Arginine','cpd00051'], #EXs : 3\n",
    "    ['L-Asparagine','cpd00132'], #EXs : 4\n",
    "    ['L-Aspartate','cpd00041'], #EXs : 5\n",
    "    ['L-Cysteine','cpd00084'], #EXs : 7\n",
    "    ['L-Glutamate','cpd00023'], #EXs : 8\n",
    "    ['L-Glutamine','cpd00053'], #EXs : 9\n",
    "    ['L-Histidine','cpd00119'], #EXs : 10\n",
    "    ['L-Isoleucine','cpd00322'], #EXs : 11\n",
    "    ['L-Leucine','cpd00107'], #EXs : 12\n",
    "    ['L-Lysine','cpd00039'], #EXs : 13\n",
    "    ['L-Methionine','cpd00060'], #EXs : 14\n",
    "    ['L-Phenylalanine','cpd00066'], #EXs : 15\n",
    "    ['L-Proline','cpd00129'], #EXs : 16\n",
    "    ['L-Serine','cpd00054'], #EXs : 17\n",
    "    ['L-Threonine','cpd00161'], #EXs : 18\n",
    "    ['L-Tryptophan','cpd00065'], #EXs : 19\n",
    "    ['L-Tyrosine','cpd00069'], #EXs : 20\n",
    "    ['L-Valine','cpd00156'], #EXs : 21\n",
    "    ['H2O2','cpd00025'],\n",
    "    ['L-Lactate','cpd00159'],\n",
    "    ['Acetate','cpd00029'],\n",
    "    ['Butyrate','cpd00211'],\n",
    "    ['isobutyrate','cpd01711'], \n",
    "    ['GABA','cpd00281'],\n",
    "    ['ethanol','cpd00363'],\n",
    "    ['Propionate','cpd00141'],\n",
    "    ['formate','cpd00047'],\n",
    "    ['Valerate','cpd00597'],\n",
    "#     ['Isovaleric acid','cpd05178'], # Not in universal?\n",
    "    ['TMAO','cpd00811'], # (CH3)3NO\n",
    "    ['Indole-3-(carb)aldehyde','cpd05401'],\n",
    "#     ['Acetaldehyde','cpd00071'],\n",
    "    ['Deoxycholate','cpd02733'],\n",
    "    ['Chorismate','cpd00216'],\n",
    "    ['Hexanoate','cpd01113']\n",
    "]\n",
    "\n",
    "carbon_sources = [\n",
    "    ['D-Glucose','cpd00027'],\n",
    "    ['4-Hydroxybenzoate','cpd00136'], #EXs : found in coconuts\n",
    "    ['2-keto-3-deoxygluconate','cpd00176'], #EXs : degraded pectin product\n",
    "    ['Amylotriose','cpd01262'], #EXs : \n",
    "#     ['CELB','cpd00158'], #EXs : Cellobiose\n",
    "    ['D-Fructose','cpd00082'], #EXs : \n",
    "    ['D-Mannitol','cpd00314'], #EXs : sweetener the is poorly absorbed in the gut\n",
    "    ['D-Mannose','cpd00138'], #EXs : related to mucin\n",
    "    ['Ribose','cpd00105'], #EXs : \n",
    "    ['Dextrin','cpd11594'], #EXs : \n",
    "    ['Dulcose','cpd01171'], #EXs : Galactitol\n",
    "    ['GLCN','cpd00222'], #EXs : Gluconate \n",
    "    ['GLUM','cpd00276'], #EXs : Glucosamine\n",
    "    ['Galactose','cpd00108'], #EXs : \n",
    "    ['L-Arabinose','cpd00224'], #EXs : \n",
    "    ['L-Inositol','cpd00121'], #EXs : \n",
    "    ['L-Lactate','cpd00159'], #EXs : \n",
    "    ['L-Malate','cpd00130'], #EXs : \n",
    "    ['Glycerol','cpd00100'], #EXs : \n",
    "#     ['LACT','cpd00208'], #EXs : lactose\n",
    "    ['Maltohexaose','cpd01329'], #EXs : \n",
    "#     ['Maltose','cpd00179'], #EXs : \n",
    "    ['Melibiose','cpd03198'], #EXs : \n",
    "    ['Palmitate','cpd00214'], #EXs : \n",
    "    ['Propionate','cpd00141'], #EXs : \n",
    "#     ['Salicin','cpd01030'], #EXs : \n",
    "    ['Sorbitol','cpd00588'], #EXs : \n",
    "    ['Stachyose','cpd01133'], #EXs : \n",
    "    ['Succinate','cpd00036'], #EXs : \n",
    "#     ['Sucrose','cpd00076'], #EXs : \n",
    "#     ['TRHL','cpd00794'], #EXs : Trehalose\n",
    "    ['Ursin','cpd03696'], #EXs : Arbutin\n",
    "    ['Xylose','cpd00154'], #EXs : \n",
    "    ['hexadecenoate','cpd15237'] #EXs : \n",
    "]\n",
    "\n",
    "# Nitrogen Sources\n",
    "nitrogen_sources = [\n",
    "    ['NH3','cpd00013'], #EXs : \n",
    "    ['Allantoin','cpd01092'], #EXs : degradation product of purines\n",
    "    ['BET','cpd00540'], #EXs : Betaine\n",
    "    ['Choline','cpd00098'], #EXs : Found in milk\n",
    "    ['Nitrate','cpd00209'], #EXs : \n",
    "    ['Nitrite','cpd00075'], #EXs : \n",
    "    ['Spermidine','cpd00264'], #EXs : \n",
    "    ['Urea','cpd00073'], #EXs : \n",
    "    ['crotonobetaine','cpd08305'] #EXs : \n",
    "]\n",
    "\n",
    "print(str(len(products)*len(carbon_sources)*len(nitrogen_sources)*20/3600) + 'hours')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pFBA gapfiller\n",
    "def pfba_gapfill(model, reaction_bag, likelihoods, obj=None, obj_lb=10., obj_constraint=False,\n",
    "                 iters=1, tasks=None, task_lb=0.05, \n",
    "                 add_exchanges=True, extracellular='e'):\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Save some basic network info for downstream membership testing\n",
    "    orig_rxn_ids = set([str(x.id) for x in model.reactions])\n",
    "    orig_cpd_ids = set([str(y.id) for y in model.metabolites])\n",
    "\n",
    "    # Get model objective reaction ID\n",
    "    if obj == None:\n",
    "        obj = get_objective(model)\n",
    "    else:\n",
    "        obj = obj\n",
    "    \n",
    "    # Modify universal reaction bag\n",
    "    new_rxn_ids = set()\n",
    "    with reaction_bag as universal:\n",
    "\n",
    "        # Remove overlapping reactions from universal bag, and reset objective if needed\n",
    "        orig_rxns = list(copy.deepcopy(model.reactions))\n",
    "            \n",
    "        # Add pFBA to universal model and add model reactions\n",
    "        \n",
    "        add_pfba_likely(universal, likelihoods)\n",
    "        \n",
    "        universal.add_reactions(orig_rxns)\n",
    "        \n",
    "        # If previous objective not set as constraint, set minimum lower bound\n",
    "        if obj_constraint == False: \n",
    "            universal.reactions.get_by_id(obj).lower_bound = obj_lb\n",
    "        \n",
    "        # Run FBA and save solution\n",
    "        solution = universal.optimize()\n",
    "#         print([bound.id for bound in universal.boundary if bound.lower_bound != 0.0 and bound.upper_bound != 0.0 and bound.id.startswith('EX')])\n",
    "        \n",
    "        # Identify which reactions carry flux in solution\n",
    "        rxns = list(solution.fluxes.index)\n",
    "        fluxes = list(solution.fluxes)\n",
    "        for flux in range(0, len(fluxes)):\n",
    "            if abs(fluxes[flux]) > 1e-6:\n",
    "                new_rxn_ids |= set([rxns[flux]])\n",
    "        \n",
    "    # Screen new reaction IDs\n",
    "    if obj in new_rxn_ids: new_rxn_ids.remove(obj)\n",
    "    for rxn in orig_rxn_ids:\n",
    "        try:\n",
    "            new_rxn_ids.remove(rxn)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Get reactions and metabolites to be added to the model\n",
    "    new_rxns = copy.deepcopy([reaction_bag.reactions.get_by_id(rxn) for rxn in new_rxn_ids])\n",
    "    new_cpd_ids = set()\n",
    "    for rxn in new_rxns: new_cpd_ids |= set([str(x.id) for x in list(rxn.metabolites)])\n",
    "    new_cpd_ids = new_cpd_ids.difference(orig_cpd_ids)\n",
    "    new_cpds = copy.deepcopy([reaction_bag.metabolites.get_by_id(cpd) for cpd in new_cpd_ids])\n",
    "    \n",
    "    # Copy model and gapfill\n",
    "    new_model = copy.deepcopy(model)\n",
    "    new_model.add_metabolites(new_cpds)\n",
    "    new_model.add_reactions(new_rxns)\n",
    "    \n",
    "    duration = int(round(time.time() - start_time))\n",
    "    print('Took ' + str(duration) + ' seconds to gapfill ' + str(len(new_rxn_ids)) + \\\n",
    "          ' reactions and ' + str(len(new_cpd_ids)) + ' metabolites.') \n",
    "    \n",
    "    return {'NewModel':new_model, 'gaps':new_rxn_ids, 'mets':new_cpd_ids}\n",
    "\n",
    "def add_pfba_likely(model, likelihoods, objective=None, fraction_of_optimum=1.0):\n",
    "    if objective is not None:\n",
    "        model.objective = objective\n",
    "    if model.solver.objective.name == '_pfba_objective':\n",
    "        raise ValueError('The model already has a pFBA objective.')\n",
    "    sutil.fix_objective_as_constraint(model, fraction=fraction_of_optimum)\n",
    "    reaction_variables = ((rxn.forward_variable, rxn.reverse_variable)\n",
    "                          for rxn in model.reactions)\n",
    "    variables = chain(*reaction_variables)\n",
    "    dict1 = {}\n",
    "    fail_report = []\n",
    "    model_reactions = [rxn.id.split('_')[0] for rxn in model.reactions if rxn.id.startswith('rxn')]\n",
    "    for v in variables:\n",
    "        if set([str(v.name.split('_')[0])]).issubset(set(model_reactions)) and str(v.name.split('_')[0]).startswith('rxn'):\n",
    "            rxn_id = (v.name.split('_')[0] + '_c')\n",
    "            try:\n",
    "                dict1[v] = max([0.0, 1.0 - likelihoods[rxn_id]])\n",
    "            except:\n",
    "                try:\n",
    "                    dict1[v] = 1.0\n",
    "                except:\n",
    "                    print('FAILED')\n",
    "                    pass\n",
    "                pass\n",
    "            \n",
    "        elif str(v.name.split('_')[0]).startswith('DM'):\n",
    "            dict1[v] = 1.0\n",
    "        else:\n",
    "            fail_report.append(1)\n",
    "    model.objective = model.problem.Objective(Zero, direction='min', sloppy=True, name=\"_pfba_objective\")\n",
    "    model.objective.set_linear_coefficients(dict1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in models...Adding Water...Set-up Universal...Set-up Model...removing reactions from universal...42.0seconds to complete\n"
     ]
    }
   ],
   "source": [
    "# Using pFBA with new media components (RNA bases + thymidine...) \n",
    "# Remove reaction likelihoods of zero from model\n",
    "# Add demands for all metabolites in model to avoid any reactions being blocked\n",
    "# Weighted pFBA gapfill solution\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "sys.stdout.write('Loading in models...')\n",
    "\n",
    "universal = cobra.io.load_json_model(\"../Data/GramPosUni.json\")\n",
    "genome_id = '220668.9'\n",
    "model = cobra.io.read_sbml_model('../gap_models/'+ genome_id +'.xml')\n",
    "likelihoods = pickle.load(open('../likelihoods/'+ genome_id +'.probs'))\n",
    "\n",
    "sys.stdout.write('Adding Water...')\n",
    "\n",
    "# Ensure free diffusion of water\n",
    "model.reactions.get_by_id('rxn05319_c').name = \"Water transport\"\n",
    "model.reactions.get_by_id('rxn05319_c').bounds = (-1000., 1000.)\n",
    "\n",
    "sys.stdout.write('Set-up Universal...')\n",
    "\n",
    "# Add demand for all metabolites in Universal model to stop blocked reactions\n",
    "all_mets = []\n",
    "for met in universal.metabolites:\n",
    "    if (met.id.endswith('_c')):\n",
    "        universal.add_boundary(met, type='demand')\n",
    "\n",
    "### Set Up Model: remove low likelihood reactions\n",
    "sys.stdout.write('Set-up Model...')\n",
    "low_like_model = []\n",
    "for rxn in model.reactions:\n",
    "    if rxn.id.startswith('rxn'):\n",
    "        try:\n",
    "            if likelihoods[rxn.id] <= 0.1:\n",
    "                low_like_model.append(rxn.id)\n",
    "        except:\n",
    "            pass\n",
    "model_rxns_to_remove = [model.reactions.get_by_id(rxn) for rxn in low_like_model]\n",
    "model.remove_reactions(model_rxns_to_remove)\n",
    "\n",
    "# Create and set specific Media List\n",
    "# media_list = bsm + M9_sources + rna_bases # + nitrogen + carbon\n",
    "# set_media(model, media_list, universal, verbose=False)\n",
    "# set_media(universal, media_list, universal, verbose=False)\n",
    "\n",
    "# Remove model reactions from universal\n",
    "orig_rxn_ids = set([str(x.id) for x in model.reactions])\n",
    "univ_rxn_ids = set([str(z.id) for z in universal.reactions])\n",
    "overlap_rxn_ids = univ_rxn_ids.intersection(orig_rxn_ids)\n",
    "sys.stdout.write('removing reactions from universal...')\n",
    "for rxn in overlap_rxn_ids: \n",
    "    universal.reactions.get_by_id(rxn).remove_from_model()\n",
    "\n",
    "print(str(round(time.time() - t)) + 'seconds to complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loop0 Gapfilling cpd00117_c ...Took 22 seconds to gapfill 2 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00117_c is 0.5173929430770764...\n",
      "Loop1 Gapfilling cpd00186_c ...Took 20 seconds to gapfill 3 reactions and 1 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00186_c is 0.3576984405744588...\n",
      "Loop2 Gapfilling cpd00637_c ...Took 20 seconds to gapfill 15 reactions and 1 metabolites.\n",
      "pFBA...364.0...Ave likelihood of: cpd00637_c is 0.4056670026600993...\n",
      "Loop3 Gapfilling cpd00550_c ...Took 23 seconds to gapfill 3 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00550_c is 0.42506111470271607...\n",
      "Loop4 Gapfilling cpd00033_c ...Took 21 seconds to gapfill 4 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00033_c is 0.5136577493313834...\n",
      "Loop5 Gapfilling cpd00035_c ...Took 18 seconds to gapfill 2 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00035_c is 0.554409442255843...\n",
      "Loop6 Gapfilling cpd00051_c ...Took 21 seconds to gapfill 10 reactions and 2 metabolites.\n",
      "pFBA...250.0...Ave likelihood of: cpd00051_c is 0.4915137661553638...\n",
      "Loop7 Gapfilling cpd00132_c ...Took 19 seconds to gapfill 6 reactions and 2 metabolites.\n",
      "pFBA...222.0...demands added\n",
      "Ave likelihood of: cpd00132_c is 0.5497447502941916...\n",
      "Loop8 Gapfilling cpd00041_c ...Took 20 seconds to gapfill 2 reactions and 0 metabolites.\n",
      "pFBA...500.0...Ave likelihood of: cpd00041_c is 0.48105844915985196...\n",
      "Loop9 Gapfilling cpd00084_c ...Took 19 seconds to gapfill 4 reactions and 0 metabolites.\n",
      "pFBA...692.0...Ave likelihood of: cpd00084_c is 0.4685009545562413...\n",
      "Loop10 Gapfilling cpd00023_c ...Took 18 seconds to gapfill 3 reactions and 1 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00023_c is 0.458944399647369...\n",
      "Loop11 Gapfilling cpd00053_c ...Took 19 seconds to gapfill 3 reactions and 1 metabolites.\n",
      "pFBA...500.0...Ave likelihood of: cpd00053_c is 0.4908274791665371...\n",
      "Loop12 Gapfilling cpd00119_c ...Took 18 seconds to gapfill 5 reactions and 1 metabolites.\n",
      "pFBA...409.0...demands added\n",
      "Ave likelihood of: cpd00119_c is 0.5267093871682991...\n",
      "Loop13 Gapfilling cpd00322_c ...Took 19 seconds to gapfill 6 reactions and 2 metabolites.\n",
      "pFBA...250.0...Ave likelihood of: cpd00322_c is 0.5142942431743567...\n",
      "Loop14 Gapfilling cpd00107_c ...Took 22 seconds to gapfill 13 reactions and 4 metabolites.\n",
      "pFBA...426.0...demands added\n",
      "Ave likelihood of: cpd00107_c is 0.4707731525983245...\n",
      "Loop15 Gapfilling cpd00039_c ...Took 20 seconds to gapfill 5 reactions and 1 metabolites.\n",
      "pFBA...333.0...Ave likelihood of: cpd00039_c is 0.48706720834805783...\n",
      "Loop16 Gapfilling cpd00060_c ...Took 17 seconds to gapfill 14 reactions and 1 metabolites.\n",
      "pFBA...364.0...Ave likelihood of: cpd00060_c is 0.41298216012258954...\n",
      "Loop17 Gapfilling cpd00066_c ...Took 21 seconds to gapfill 5 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00066_c is 0.5834542030754714...\n",
      "Loop18 Gapfilling cpd00129_c ...Took 19 seconds to gapfill 3 reactions and 1 metabolites.\n",
      "pFBA...667.0...Ave likelihood of: cpd00129_c is 0.5156836338038608...\n",
      "Loop19 Gapfilling cpd00054_c ...Took 20 seconds to gapfill 2 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00054_c is 0.45034312744676314...\n",
      "Loop20 Gapfilling cpd00161_c ...Took 20 seconds to gapfill 2 reactions and 0 metabolites.\n",
      "pFBA...333.0...Ave likelihood of: cpd00161_c is 0.5355121329211027...\n",
      "Loop21 Gapfilling cpd00065_c ...Took 20 seconds to gapfill 9 reactions and 2 metabolites.\n",
      "pFBA...333.0...demands added\n",
      "Ave likelihood of: cpd00065_c is 0.513691597870001...\n",
      "Loop22 Gapfilling cpd00069_c ...Took 20 seconds to gapfill 4 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00069_c is 0.5384916791777978...\n",
      "Loop23 Gapfilling cpd00156_c ...Took 20 seconds to gapfill 4 reactions and 1 metabolites.\n",
      "pFBA...500.0...Ave likelihood of: cpd00156_c is 0.46710105818072245...\n",
      "Loop24 Gapfilling cpd00025_c ...Took 20 seconds to gapfill 0 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00025_c is 0.4892862529018511...\n",
      "Loop25 Gapfilling cpd00159_c ...Took 20 seconds to gapfill 1 reactions and 0 metabolites.\n",
      "pFBA...1000.0...Ave likelihood of: cpd00159_c is 0.4748332426340034...\n",
      "Loop26 Gapfilling cpd00029_c ...Took 19 seconds to gapfill 1 reactions and 0 metabolites.\n",
      "pFBA...750.0...Ave likelihood of: cpd00029_c is 0.6122119043505102...\n",
      "Loop27 Gapfilling cpd00211_c ...Took 20 seconds to gapfill 8 reactions and 3 metabolites.\n",
      "pFBA...250.0...Ave likelihood of: cpd00211_c is 0.5559515582601068...\n",
      "Loop28 Gapfilling cpd01711_c ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cobra/util/solver.py:408 \u001b[1;31mUserWarning\u001b[0m: solver status is 'infeasible'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 16 seconds to gapfill 279 reactions and 138 metabolites.\n",
      "pFBA...0.0...Ave likelihood of: cpd01711_c is nan...\n",
      "Loop29 Gapfilling cpd00281_c ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjmoutinho/.local/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2957 \u001b[1;31mRuntimeWarning\u001b[0m: Mean of empty slice.\n",
      "/home/tjmoutinho/.local/lib/python2.7/site-packages/numpy/core/_methods.py:80 \u001b[1;31mRuntimeWarning\u001b[0m: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 20 seconds to gapfill 3 reactions and 1 metabolites.\n",
      "pFBA...500.0...Ave likelihood of: cpd00281_c is 0.34854847406721956...\n",
      "Loop30 Gapfilling cpd00363_c ...Took 19 seconds to gapfill 1 reactions and 0 metabolites.\n",
      "pFBA...375.0...Ave likelihood of: cpd00363_c is 0.5755424049934691...\n",
      "Loop31 Gapfilling cpd00141_c ...Took 21 seconds to gapfill 3 reactions and 0 metabolites.\n",
      "pFBA...231.0...Ave likelihood of: cpd00141_c is 0.610616965351919...\n",
      "Loop32 Gapfilling cpd00047_c ...Took 20 seconds to gapfill 6 reactions and 1 metabolites.\n",
      "pFBA...643.0...demands added\n",
      "Ave likelihood of: cpd00047_c is 0.4868311002873278...\n",
      "Loop33 Gapfilling cpd00597_c ...Took 16 seconds to gapfill 368 reactions and 181 metabolites.\n",
      "pFBA...0.0...Ave likelihood of: cpd00597_c is nan...\n",
      "Loop34 "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cpd05178_c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d432c179a0b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetabolites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                         \u001b[0mtemp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_metabolites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniversal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetabolites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                         \u001b[0mmetabolite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetabolites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0mdemand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetabolite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'demand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tjmoutinho/.local/lib/python2.7/site-packages/cobra/core/dictlist.pyc\u001b[0m in \u001b[0;36mget_by_id\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;34m\"\"\"return the element with a matching id\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cpd05178_c'"
     ]
    }
   ],
   "source": [
    "# Run through each amino acid to check for production\n",
    "global_time = time.time()\n",
    "counter = 0\n",
    "\n",
    "total_dataset_dict = {}\n",
    "carb_idx = 0\n",
    "\n",
    "for carbon in carbon_sources:\n",
    "    nit_idx = 0\n",
    "    for nitrogen in nitrogen_sources:\n",
    "        # Create and set specific Media List\n",
    "        media_list = bsm + M9_sources + rna_bases + [nitrogen] + [carbon]\n",
    "        set_media(model, media_list, universal, verbose=False)\n",
    "        \n",
    "        product_idx = 0\n",
    "        for product_list in products:\n",
    "            t = time.time()\n",
    "            sys.stdout.write('\\n'+ 'Loop' + str(counter) + ' ')\n",
    "            product = product_list[1]+'_c'\n",
    "            product_name = product_list[0]\n",
    "            \n",
    "            with model as temp_model, universal as temp_universal:\n",
    "                \n",
    "                try:\n",
    "                    metabolite = temp_model.metabolites.get_by_id(product)\n",
    "                    demand = temp_model.add_boundary(metabolite, type='demand')\n",
    "                    temp_model.objective = demand\n",
    "                except:\n",
    "                    if set(product).issubset(set([met.id for met in model.metabolites])) == 0:\n",
    "                        temp_model.add_metabolites(copy.deepcopy(temp_universal.metabolites.get_by_id(product)))\n",
    "                        metabolite = temp_model.metabolites.get_by_id(product)\n",
    "                        demand = temp_model.add_boundary(metabolite, type='demand')\n",
    "                        temp_model.objective = demand\n",
    "                \n",
    "                temp_universal.reactions.get_by_id(demand.id).remove_from_model()\n",
    "                \n",
    "                sys.stdout.write('Gapfilling ' + product + '...')\n",
    "                dont_continue = 0\n",
    "#                 new_gapfill_data = pfba_gapfill(temp_model, temp_universal, likelihoods, obj=demand.id, obj_lb=10., obj_constraint=False, iters=1, add_exchanges=False)\n",
    "                try:\n",
    "                    new_gapfill_data = pfba_gapfill(temp_model, temp_universal, likelihoods, obj=demand.id, obj_lb=10., obj_constraint=False, iters=1, add_exchanges=False)\n",
    "                except:\n",
    "                    try:\n",
    "                        sys.stdout.write('Restart Gapfilling...')\n",
    "                        new_gapfill_data = pfba_gapfill(temp_model, temp_universal, likelihoods, obj=demand.id, obj_lb=10., obj_constraint=False, iters=1, add_exchanges=False)\n",
    "                    except:\n",
    "                        sys.stdout.write('Failed Gapfilling...')\n",
    "                        dont_continue = 1\n",
    "                        pass\n",
    "                \n",
    "                gaps_to_fill = new_gapfill_data['gaps']\n",
    "                new_model = new_gapfill_data['NewModel']\n",
    "                mets_added = new_gapfill_data['mets']\n",
    "                \n",
    "                if dont_continue == 0:\n",
    "                    # Optimize with filled pathway\n",
    "                    sys.stdout.write('pFBA...')\n",
    "                    solution = pfba(new_model, objective = demand)\n",
    "                    sys.stdout.write(str(round(new_model.slim_optimize())) + '...')\n",
    "                    \n",
    "                    if new_model.slim_optimize() <= 1.0:\n",
    "                        dont_continue = 1 \n",
    "                    \n",
    "                    if dont_continue == 0:\n",
    "                    \n",
    "                        # Find reactions that carry flux\n",
    "                        df = solution.fluxes.to_frame()\n",
    "                        active = df.loc[(abs(df['fluxes'])) > 0.1]\n",
    "\n",
    "                        demand_list = []\n",
    "                        for rxn_id in active.index:\n",
    "                            if rxn_id.startswith('DM') and rxn_id != demand.id:\n",
    "                                demand_list.append(rxn_id)\n",
    "                                print('demands added')\n",
    "\n",
    "                        # Acquire likelihood scores for reactions that carry flux\n",
    "                        flux_rxns = []\n",
    "                        like_list = []\n",
    "                        gap_flux_rxns = []\n",
    "                        gap_like_list = []\n",
    "                        path_flux_rxns = []\n",
    "                        path_like_list = []\n",
    "                        for rxn in list(active.index):\n",
    "                            if rxn in gaps_to_fill and rxn.startswith('rxn'):\n",
    "                                try:\n",
    "                                    gap_flux_rxns.append([str(rxn),likelihoods[str(rxn)]])\n",
    "                                    gap_like_list.append(likelihoods[str(rxn)])\n",
    "                                except:\n",
    "                                    pass\n",
    "                            if rxn not in gaps_to_fill and rxn.startswith('rxn'):\n",
    "                                try:\n",
    "                                    path_flux_rxns.append([str(rxn),likelihoods[str(rxn)]])\n",
    "                                    path_like_list.append(likelihoods[str(rxn)])\n",
    "                                except:\n",
    "                                    pass\n",
    "                            if rxn.startswith('rxn'):\n",
    "                                try:\n",
    "                                    flux_rxns.append([str(rxn),likelihoods[str(rxn)]])\n",
    "                                    like_list.append(likelihoods[str(rxn)])\n",
    "                                except:\n",
    "                                    pass\n",
    "                        avg_like = np.mean(like_list)\n",
    "\n",
    "                        opt_before = model.slim_optimize()\n",
    "                        if opt_before > 0.0:\n",
    "                            gap_avg_like = []\n",
    "                        else:\n",
    "                            gap_avg_like = np.mean(gap_like_list)\n",
    "                        path_avg_like = np.mean(path_like_list)\n",
    "                        sys.stdout.write('Ave likelihood of: ' + product + ' is ' + str(avg_like) + '...')\n",
    "\n",
    "                        counter += 1\n",
    "\n",
    "                        report_dict = {}\n",
    "                        report_dict['Model_ID'] = genome_id\n",
    "                        report_dict['Carbon'] = carbon\n",
    "                        report_dict['Nitrogen'] = nitrogen\n",
    "                        report_dict['objective'] = product_name\n",
    "                        report_dict['opt_before'] = opt_before\n",
    "                        report_dict['opt_after'] = new_model.slim_optimize()\n",
    "                        report_dict['avg_path_like'] = avg_like\n",
    "                        report_dict['gap_avg_like'] = gap_avg_like\n",
    "                        report_dict['path_avg_like'] = path_avg_like\n",
    "                        report_dict['gaps_filled'] = gaps_to_fill\n",
    "                        report_dict['mets_added'] = mets_added\n",
    "                        report_dict['reactions_w_flux'] = flux_rxns\n",
    "                        report_dict['gaps_w_flux'] = gap_flux_rxns\n",
    "                        report_dict['path_w_flux'] = path_flux_rxns\n",
    "                        report_dict['active_rxns'] = active\n",
    "                        report_dict['demands'] = demand_list\n",
    "\n",
    "                        report_dict_ID = genome_id + ':' + str(carb_idx) + '.' + str(nit_idx) + '.' + str(product_idx)\n",
    "                        total_dataset_dict[report_dict_ID] = report_dict\n",
    "                        product_idx += 1 # Keep track to which product is being maximized\n",
    "                    \n",
    "#                     elapsed = time.time() - t\n",
    "#                     sys.stdout.write('Run time: ' + str(elapsed/60) + \" [mins]...\")\n",
    "                    \n",
    "                if dont_continue == 1:\n",
    "                    counter += 1\n",
    "                    \n",
    "                    report_dict = {}\n",
    "                    report_dict['Model_ID'] = genome_id\n",
    "                    report_dict['Carbon'] = carbon\n",
    "                    report_dict['Nitrogen'] = nitrogen\n",
    "                    report_dict['objective'] = product_name\n",
    "                    report_dict['opt_before'] = \"Failed to gapfill\"\n",
    "                    report_dict['opt_after'] = \"Failed to gapfill\"\n",
    "                    report_dict['avg_path_like'] = \"Failed to gapfill\"\n",
    "                    report_dict['gap_avg_like'] = \"Failed to gapfill\"\n",
    "                    report_dict['path_avg_like'] = \"Failed to gapfill\"\n",
    "                    report_dict['gaps_filled'] = \"Failed to gapfill\"\n",
    "                    report_dict['mets_added'] = \"Failed to gapfill\"\n",
    "                    report_dict['reactions_w_flux'] = \"Failed to gapfill\"\n",
    "                    report_dict['gaps_w_flux'] = \"Failed to gapfill\"\n",
    "                    report_dict['path_w_flux'] = \"Failed to gapfill\"\n",
    "                    report_dict['active_rxns'] = \"Failed to gapfill\"\n",
    "                    report_dict['demands'] = \"Failed to gapfill\"\n",
    "                    \n",
    "                    report_dict_ID = genome_id + ':' + str(carb_idx) + '.' + str(nit_idx) + '.' + str(product_idx)\n",
    "                    total_dataset_dict[report_dict_ID] = report_dict\n",
    "                    product_idx += 1 #Keep track to which product is being maximized\n",
    "                    \n",
    "#                     elapsed = time.time() - t\n",
    "#                     sys.stdout.write('Run time: ' + str(elapsed/60) + \" [mins]...\")\n",
    "        nit_idx += 1\n",
    "    carb_idx += 1\n",
    "file_name = \"../metabolic_output/%s_V2.data\" % (genome_id) # CHANGE BACK TO CORRECT NAME\n",
    "pickle.dump(total_dataset_dict, open(file_name, \"wb\"))\n",
    "\n",
    "print('\\n'+ str((time.time() - global_time)/60) + 'mins to complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
